{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LFP effects for stimulation on the different channels\n",
    "# Select 2-3 stimulation and recording channels\n",
    "# Plot LFPs, PSDs, STFT, and cross-channel coherence\n",
    "# Pre-stim only\n",
    "\n",
    "#Import Libraries\n",
    "# | echo: false\n",
    "# | warning: false\n",
    "%run C:/Users/27707/Documents/jhu_master/lab/importrhsutilities.py\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spikeinterface as si  # import core only\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.extractors as sse\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.curation as scur\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "from probeinterface import Probe, ProbeGroup\n",
    "from probeinterface import generate_linear_probe, generate_multi_shank\n",
    "from probeinterface import combine_probes\n",
    "from probeinterface.plotting import plot_probe\n",
    "\n",
    "import datetime\n",
    "from uuid import uuid4\n",
    "\n",
    "import numpy as np\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "from pynwb import NWBHDF5IO, NWBFile\n",
    "from pynwb.ecephys import LFP, ElectricalSeries\n",
    "from pprint import pprint\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_names = ['BO3_O5W_Sti_Day1_5uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_10uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_20uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_30uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_40uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_50uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_60uA_m.nwb'\n",
    "                   ]\n",
    "\n",
    "amps = ['5ua','10ua','20ua',\n",
    "        '30ua','40ua','50ua','60ua']\n",
    "intan_path = 'C:/Users/27707/Documents/jhu_master/LFP_analysis/2024-07-26_DG_3elec/Experimental Set_Final Round_Batch 27/5 Week Old Organoid/Stimulation Day1/'\n",
    "intan_folders = ['5uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_5uA_233uS_240625_161619/merged/',\n",
    "                 '10uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_10uA_233uS_240625_162505/merged/',\n",
    "                 '20uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_20uA_233uS_240625_163352/merged/',\n",
    "                 '30uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_30uA_233uS_240625_164235/merged/',\n",
    "                 '40uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_40uA_233uS_240625_165135/merged/',\n",
    "                 '50uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_50uA_233uS_240625_170022/merged/',\n",
    "                 '60uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_60uA_233uS_240625_170906/merged/'\n",
    "                 ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_intan_data(channel_names, signal_data_name,results):\n",
    "    dfs = []\n",
    "    i = 0\n",
    "    for res in results:\n",
    "        #save times for later processing\n",
    "        dict_data = {}\n",
    "        dict_data['time'] = res['t']\n",
    "\n",
    "        #add data for each channel to master df\n",
    "        j = 0\n",
    "        for chan in channel_names:\n",
    "            channel_found, signal_type, signal_index = find_channel_in_header(chan, res)\n",
    "            dict_data[chan] = res[signal_data_name][signal_index,:]/1000 # data is in mV but NWB electrical series type expects V\n",
    "            j += 1\n",
    "        df = pd.DataFrame.from_dict(dict_data)\n",
    "        dfs.append(df)\n",
    "        i+=1\n",
    "    rec_data = pd.concat([dfs[i] for i in range(len(dfs))], axis=0)\n",
    "    rec_data = rec_data.set_index('time')\n",
    "    return rec_data\n",
    "\n",
    "def pull_files(recording_name,fpath='/media/t7/surpass/electrophysiology/Gracias Data/ExperimentalSet_Round2/'):\n",
    "    '''\n",
    "    input:\n",
    "    day - int - day number\n",
    "    recording_name - string - string name of recording folder\n",
    "    '''\n",
    "    filepath = fpath + recording_name + '/*.rhs'\n",
    "    print(filepath)\n",
    "    fnames = glob.glob(filepath)\n",
    "    print(fnames)\n",
    "    results = 0\n",
    "    for i in np.arange(len(fnames)):\n",
    "        res, data_present = load_file(fnames[i])\n",
    "        if i == 0:\n",
    "            results = [res]\n",
    "        else:\n",
    "            results.append(res)\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times_array = []\n",
    "for i in range(len(recording_names)):\n",
    "    BO7_res = pull_files(intan_folders[i], intan_path)\n",
    "    stim_names_BO7 = ['STIM_A-000','STIM_A-002','STIM_A-004']\n",
    "    stim_BO7 = all_intan_data(stim_names_BO7,'stim_data',BO7_res)\n",
    "    stim_times = stim_BO7.loc[(stim_BO7['STIM_A-000'] != 0) | (stim_BO7['STIM_A-002'] != 0) | (stim_BO7['STIM_A-004'] != 0)].index\n",
    "    stim_times_array.append(stim_times.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_start_array = []\n",
    "stim_end_array = []\n",
    "for stim in stim_times_array:\n",
    "    stim = np.insert(stim,0,0)\n",
    "    stim_times_diff = np.diff(stim)\n",
    "    stim_start = stim[np.where(stim_times_diff > 1)[0]+1]\n",
    "    stim_end = stim[np.where(stim_times_diff > 1)[0][1:]]\n",
    "    stim_end = np.concatenate((stim_end,[stim[-1]]))\n",
    "    print(stim_start)\n",
    "    print(stim_end)\n",
    "    stim_start_array.append(stim_start)\n",
    "    stim_end_array.append(stim_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_probe():\n",
    "    north = generate_linear_probe(num_elec=1)\n",
    "    north.rotate(180)\n",
    "    north.set_contacts(positions=[[0,75]])\n",
    "\n",
    "\n",
    "    east = generate_linear_probe(num_elec=1)\n",
    "    east.rotate(90)\n",
    "    east.set_contacts(positions=[[75,0]])\n",
    "\n",
    "    west = generate_linear_probe(num_elec=1)\n",
    "    west.rotate(-90)\n",
    "    west.set_contacts(positions=[[-75,0]])\n",
    "\n",
    "    multi_shank = combine_probes([west, east, north])\n",
    "    plot_probe(multi_shank)\n",
    "    plt.show()\n",
    "    multi_shank.set_device_channel_indices([0,1,2])\n",
    "    return multi_shank\n",
    "\n",
    "def filterbank(recording):\n",
    "    recording_delta = spre.bandpass_filter(recording, freq_min=1, freq_max=4) #delta- moutri paper\n",
    "    recording_100_200 = spre.bandpass_filter(recording, freq_min=100, freq_max=200) #'gamma'- moutri paper\n",
    "    recording_200_400 = spre.bandpass_filter(recording, freq_min=200, freq_max=400) #'gamma'- moutri paper\n",
    "    recording_gamma = spre.bandpass_filter(recording, freq_min=70, freq_max=110) #'ecog high gamma\n",
    "    return recording_delta, recording_100_200, recording_200_400, recording_gamma\n",
    "\n",
    "def downsample_lfp_mua(recording):\n",
    "    recording_lfp = spre.bandpass_filter(recording, freq_min=1, freq_max=400)\n",
    "    recording_lfp = spre.resample(recording_lfp, 1000)\n",
    "    recording_mua = spre.resample(spre.rectify(recording), 1000)\n",
    "    return recording_lfp, recording_mua\n",
    "\n",
    "def load_data(rec_name):\n",
    "    recording = se.read_nwb_recording(rec_name)\n",
    "    multi_shank = gen_probe()\n",
    "    recording = recording.set_probe(multi_shank)\n",
    "    return recording "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = []\n",
    "num_channels = []\n",
    "multirecording = []\n",
    "multirecording_f = []\n",
    "for i in range(len(recording_names)):\n",
    "    recording_names = [folder + 'BO3_O5W_Sti_Day1_' + amp.split('u')[0] + 'uA_m.nwb' \n",
    "                       for folder, amp in zip(intan_folders, amps)]\n",
    "    rec_names = intan_path + recording_names[i]\n",
    "    day_recording = load_data(rec_names)\n",
    "    [num_pre_samples, num_pre_channels] = day_recording.get_traces().shape # Num samples, num channels\n",
    "    num_samples.append(num_pre_samples)\n",
    "    num_channels.append(num_pre_channels)\n",
    "    print('Presample:' + str(num_pre_samples))\n",
    "\n",
    "    # Case 2: the sorter DOES NOT handle multi-segment objects\n",
    "    multirecording_1 = day_recording # The `concatenate_recordings()` mimics a mono-segment object that concatenates all segments\n",
    "    multirecording.append(day_recording) # load your recording using SpikeInterface\n",
    "    multi_shank = gen_probe()\n",
    "    multirecording_filter = spre.bandpass_filter(multirecording[i], freq_min=300, freq_max=6000)\n",
    "    multirecording_f.append(multirecording_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Calculate RMS-based thresholds for each recording and channel\n",
    "fs = 30000  # Replace with your actual sampling rate\n",
    "start_time = 5  # Start at 5 seconds\n",
    "end_time = 255  # End at 255 seconds\n",
    "num_samples = fs * (end_time - start_time)  # Calculate the number of samples for 200 seconds\n",
    "\n",
    "thresholds = []  # Initialize an empty list to store thresholds for each recording\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    thresholds_per_recording = []  # Store thresholds for each channel in the current recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        # Extract the channel data from the 10th second to the 210th second of signal\n",
    "        channel = multirecording[i].get_traces()[start_time * fs:end_time * fs, ch].astype(np.float32)\n",
    "\n",
    "        # Calculate the RMS value and determine the threshold\n",
    "        rms_value = np.sqrt(np.mean(channel**2))\n",
    "        threshold = rms_value * 5#4.5\n",
    "        thresholds_per_recording.append(threshold)\n",
    "    \n",
    "    thresholds.append(thresholds_per_recording)\n",
    "\n",
    "# Now, use the thresholds in the original artifact detection code\n",
    "ms_before = [100]\n",
    "ms_after = [100]\n",
    "artifact_frames = []\n",
    "\n",
    "# Original loop for artifact detection\n",
    "for i in range(len(recording_names)):\n",
    "    artifact_frames_per_recording = []  # Store artifact frames for each channel in a recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        channel = multirecording[i].get_traces()[:, ch].astype(np.float32)\n",
    "        \n",
    "        # Use predefined threshold for the current recording and channel\n",
    "        threshold = thresholds[i][ch]\n",
    "        print(f\"Threshold for recording {i+1}, channel {ch+1}: {threshold}\")\n",
    "        \n",
    "        # Apply the custom threshold\n",
    "        stimulation_trigger_frames = np.where(np.abs(channel) > threshold)\n",
    "\n",
    "        # Remove artifacts using the detected triggers\n",
    "        if stimulation_trigger_frames[0].size > 0:  # Check if there are any detected triggers\n",
    "            multirecording_art = spre.remove_artifacts(\n",
    "                multirecording[i],\n",
    "                list_triggers=stimulation_trigger_frames[0].tolist(),\n",
    "                ms_before=ms_before[0],  \n",
    "                ms_after=ms_after[0]\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No artifacts detected for recording {i+1}, channel {ch+1}\")\n",
    "        \n",
    "        artifact_frames_per_recording.append(stimulation_trigger_frames[0].tolist())\n",
    "\n",
    "    artifact_frames.append(artifact_frames_per_recording)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import signal\n",
    "# from spikeinterface.extractors import NumpyRecording\n",
    "# recording_art = []\n",
    "# recording_lfp = []\n",
    "# recording_mua = []\n",
    "# recording_delta = []\n",
    "# recording_100_200 = []\n",
    "# recording_200_400 = []\n",
    "# recording_gamma = []\n",
    "# recording_car = []\n",
    "# artifact_frames_resample = []\n",
    "# # Design a bandstop filter to remove frequencies between 57 Hz and 63 Hz\n",
    "# lowcut = 55.0  # Lower bound of the bandstop filter\n",
    "# highcut = 65.0  # Upper bound of the bandstop filter\n",
    "# lowcut2 = 170.0  # Lower bound of the bandstop filter\n",
    "# highcut2 = 190.0 \n",
    "# lowcut3 = 295.0  # Lower bound of the bandstop filter\n",
    "# highcut3 = 305.0 \n",
    "# lowcut4 = 60.0  # Lower bound of the bandstop filter\n",
    "# highcut4 = 70.0\n",
    "# lowcut5 = 50.0  # Lower bound of the bandstop filter\n",
    "# highcut5 = 60.0\n",
    "# sampling_rate = 30000  # Sampling rate (30 kHz)\n",
    "\n",
    "# # Design the Butterworth bandstop filter\n",
    "# b_bandstop, a_bandstop = signal.butter(3, [lowcut, highcut], btype='bandstop',fs=sampling_rate)\n",
    "# b_bandstop2, a_bandstop2 = signal.butter(3, [lowcut2, highcut2], btype='bandstop',fs=sampling_rate)\n",
    "# b_bandstop3, a_bandstop3 = signal.butter(3, [lowcut3, highcut3], btype='bandstop',fs=sampling_rate)\n",
    "# b_bandstop4, a_bandstop4 = signal.butter(3, [lowcut4, highcut4], btype='bandstop',fs=sampling_rate)\n",
    "# b_bandstop5, a_bandstop5 = signal.butter(3, [lowcut5, highcut5], btype='bandstop',fs=sampling_rate)\n",
    "\n",
    "# f0_120 = 120\n",
    "# f0_180 = 180.0  # Power line noise at 60 Hz\n",
    "# Q = 10  # Quality factor for the notch filter\n",
    "# Q1=80\n",
    "# # Q2 = 1000\n",
    "# f_240 = 240\n",
    "# f_300 =300\n",
    "# # #Create a notch filter for 60 Hz\n",
    "\n",
    "# b_60,a_60 = signal.iirnotch(60, 30, 30000)\n",
    "# b_120,a_120 = signal.iirnotch(f0_120, 200, 30000)\n",
    "# b_200, a_200 = signal.iirnotch(f0_180, 30, 30000)\n",
    "# b_240,a_240 = signal.iirnotch(f_240, 100, 30000)\n",
    "# b_300, a_300 = signal.iirnotch(f_300, Q1, 30000)\n",
    "# for i in range(len(recording_names)):\n",
    "#     rc = []\n",
    "#     for ch in range(3):\n",
    "#         # Remove artifacts for each channel\n",
    "#         recording_artifact_removed = spre.remove_artifacts(\n",
    "#             multirecording[i],\n",
    "#             list_triggers=artifact_frames[i][ch],  # Combine triggers from all channels\n",
    "#             ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "#         )\n",
    "#         channel_data_artifact_removed = recording_artifact_removed.get_traces()[:, ch]\n",
    "\n",
    "#         # Append the artifact-removed channel data to rc list\n",
    "#         rc.append(channel_data_artifact_removed)\n",
    "\n",
    "#     # Combine the channels into one array\n",
    "#     combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "#     # Create a new RecordingExtractor object with combined data\n",
    "#     sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "#     combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "\n",
    "#     # Append the filtered recording to the list\n",
    "#     recording_art.append(combined_recording)\n",
    "#     #  # Combine the channels into one array\n",
    "#     # combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "#     # # Create a new RecordingExtractor object with combined data\n",
    "#     # sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "#     # combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "\n",
    "#     # # Append the filtered recording to the list\n",
    "#     # recording_art.append(combined_recording)\n",
    "\n",
    "#     # # Step 2: Apply CAR filter after artifact removal using numpy\n",
    "#     # car_filtered_data = combined_data - np.mean(combined_data, axis=1, keepdims=True)\n",
    "#     # recording_car_filtered = NumpyRecording(traces_list=[car_filtered_data], sampling_frequency=sampling_frequency)\n",
    "#     # recording_car.append(recording_car_filtered)\n",
    "#     # Apply the 57-63 Hz bandstop filter\n",
    "#     traces_filtered = signal.filtfilt(b_60, a_60, recording_art[i].get_traces(), axis=0)\n",
    "#     # traces_filtered = signal.filtfilt(b_bandstop5, a_bandstop5, traces_filtered, axis=0)\n",
    "#     # traces_filtered = signal.filtfilt(b_bandstop4, a_bandstop4, traces_filtered, axis=0)\n",
    "#     # Continue applying other notch filters (120 Hz, 180 Hz, etc.)\n",
    "#     traces_filtered = signal.filtfilt(b_120, a_120, traces_filtered, axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_200, a_200, traces_filtered, axis=0)\n",
    "#     # traces_filtered = signal.filtfilt(b_bandstop2, a_bandstop2, traces_filtered, axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_240, a_240, traces_filtered, axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_300, a_300, traces_filtered, axis=0)\n",
    "#     # traces_filtered = signal.filtfilt(b_bandstop3, a_bandstop3, traces_filtered, axis=0)\n",
    "\n",
    "#     # Create a new RecordingExtractor with the filtered traces\n",
    "#     recording_filtered = se.NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "#     # Process LFP and MUA after filtering\n",
    "#     lfp, mua = downsample_lfp_mua(recording_filtered)\n",
    "\n",
    "#     # Apply filter bank to LFP\n",
    "#     delta, s100_200, s200_400, gamma = filterbank(lfp)\n",
    "#     recording_lfp.append(lfp)\n",
    "#     recording_mua.append(mua)\n",
    "#     recording_delta.append(delta)\n",
    "#     recording_100_200.append(s100_200)\n",
    "#     recording_200_400.append(s200_400)\n",
    "#     recording_gamma.append(gamma)\n",
    "\n",
    "#     # Resample artifact frames for further analysis\n",
    "#     stim_frames = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames[i])))\n",
    "#     artifact_frames_resample.append(stim_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spikeinterface.preprocessing import common_reference\n",
    "\n",
    "# # Step 1: Apply CAR filter after artifact removal\n",
    "# recording_art = []\n",
    "# recording_car = []  # Store recordings after applying CAR filter\n",
    "# recording_lfp = []\n",
    "# recording_mua = []\n",
    "# recording_delta = []\n",
    "# recording_100_200 = []\n",
    "# recording_200_400 = []\n",
    "# recording_gamma = []\n",
    "# artifact_frames_resample = []\n",
    "\n",
    "# # Design a bandstop filter to remove frequencies between 57 Hz and 63 Hz\n",
    "# lowcut = 55.0  # Lower bound of the bandstop filter\n",
    "# highcut = 65.0  # Upper bound of the bandstop filter\n",
    "# lowcut2 = 170.0  # Lower bound of the bandstop filter\n",
    "# highcut2 = 190.0 \n",
    "# lowcut3 = 295.0  # Lower bound of the bandstop filter\n",
    "# highcut3 = 305.0 \n",
    "# lowcut4 = 60.0  # Lower bound of the bandstop filter\n",
    "# highcut4 = 70.0\n",
    "# lowcut5 = 50.0  # Lower bound of the bandstop filter\n",
    "# highcut5 = 60.0\n",
    "# sampling_rate = 30000  # Sampling rate (30 kHz)\n",
    "\n",
    "# # Design the Butterworth bandstop filter\n",
    "# b_bandstop, a_bandstop = signal.butter(3, [lowcut, highcut], btype='bandstop', fs=sampling_rate)\n",
    "# b_bandstop2, a_bandstop2 = signal.butter(3, [lowcut2, highcut2], btype='bandstop', fs=sampling_rate)\n",
    "# b_bandstop3, a_bandstop3 = signal.butter(3, [lowcut3, highcut3], btype='bandstop', fs=sampling_rate)\n",
    "\n",
    "# f0_120 = 120\n",
    "# f0_180 = 180.0  # Power line noise at 60 Hz\n",
    "# Q = 10  # Quality factor for the notch filter\n",
    "# Q1 = 50\n",
    "# f_240 = 240\n",
    "# f_300 = 300\n",
    "\n",
    "# # Create a notch filter for 60 Hz\n",
    "# b_120, a_120 = signal.iirnotch(f0_120, 200, 30000)\n",
    "# b_240, a_240 = signal.iirnotch(f_240, 100, 30000)\n",
    "\n",
    "# for i in range(len(recording_names)):\n",
    "#     rc = []\n",
    "#     for ch in range(3):\n",
    "#         # Remove artifacts for each channel\n",
    "#         recording_artifact_removed = spre.remove_artifacts(\n",
    "#             multirecording[i],\n",
    "#             list_triggers=artifact_frames[i][ch],  # Combine triggers from all channels\n",
    "#             ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "#         )\n",
    "#         channel_data_artifact_removed = recording_artifact_removed.get_traces()[:, ch]\n",
    "\n",
    "#         # Append the artifact-removed channel data to rc list\n",
    "#         rc.append(channel_data_artifact_removed)\n",
    "\n",
    "#     # Combine the channels into one array\n",
    "#     combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "#     # Create a new RecordingExtractor object with combined data\n",
    "#     sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "#     combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "\n",
    "#     # Append the filtered recording to the list\n",
    "#     recording_art.append(combined_recording)\n",
    "\n",
    "#     # Step 2: Apply CAR filter after artifact removal using numpy\n",
    "#     car_filtered_data = combined_data - np.mean(combined_data, axis=1, keepdims=True)\n",
    "#     recording_car_filtered = NumpyRecording(traces_list=[car_filtered_data], sampling_frequency=sampling_frequency)\n",
    "#     recording_car.append(recording_car_filtered)\n",
    "\n",
    "#     # Step 3: Apply the 57-63 Hz bandstop filter\n",
    "#     traces_filtered = signal.filtfilt(b_bandstop, a_bandstop, recording_car[i].get_traces(), axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_120, a_120, traces_filtered, axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_bandstop2, a_bandstop2, traces_filtered, axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_240, a_240, traces_filtered, axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_bandstop3, a_bandstop3, traces_filtered, axis=0)\n",
    "\n",
    "#     # Create a new RecordingExtractor with the filtered traces\n",
    "#     recording_filtered = se.NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "#     # Process LFP and MUA after filtering\n",
    "#     lfp, mua = downsample_lfp_mua(recording_filtered)\n",
    "\n",
    "#     # Apply filter bank to LFP\n",
    "#     delta, s100_200, s200_400, gamma = filterbank(lfp)\n",
    "#     recording_lfp.append(lfp)\n",
    "#     recording_mua.append(mua)\n",
    "#     recording_delta.append(delta)\n",
    "#     recording_100_200.append(s100_200)\n",
    "#     recording_200_400.append(s200_400)\n",
    "#     recording_gamma.append(gamma)\n",
    "\n",
    "#     # Resample artifact frames for further analysis\n",
    "#     stim_frames = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames[i])))\n",
    "#     artifact_frames_resample.append(stim_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import numpy as np\n",
    "\n",
    "recording_art = []\n",
    "recording_lfp = []\n",
    "recording_mua = []\n",
    "recording_delta = []\n",
    "recording_100_200 = []\n",
    "recording_200_400 = []\n",
    "recording_gamma = []\n",
    "artifact_frames_resample = []\n",
    "\n",
    "# Create notch filters for specific frequencies\n",
    "# frequencies = [9.0, 18.2, 25.0, 27.2, 29.2, 36.4, 37.6, 41.4, 43.8, 45.4, 46.4, 60.0, 180.0, 300.0]\n",
    "frequencies = [60.0, 180.0, 300.0]\n",
    "qs = [60, 180, 300]  \n",
    "notch_filters = [signal.iirnotch(f, q, 30000) for f, q in zip(frequencies, qs)]\n",
    "\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    rc = []\n",
    "    for ch in range(3):\n",
    "        # Remove artifacts for each channel\n",
    "        recording_artifact_removed = spre.remove_artifacts(\n",
    "            multirecording[i],\n",
    "            list_triggers=artifact_frames[i][ch],  # Combine triggers from all channels\n",
    "            ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "        )\n",
    "        channel_data_artifact_removed = recording_artifact_removed.get_traces()[:, ch]\n",
    "\n",
    "        # Append the artifact-removed channel data to rc list\n",
    "        rc.append(channel_data_artifact_removed)\n",
    "\n",
    "    # Combine the channels into one array\n",
    "    combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "    # Create a new RecordingExtractor object with combined data\n",
    "    sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "    combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "\n",
    "    # Append the filtered recording to the list\n",
    "    recording_art.append(combined_recording)\n",
    "\n",
    "    # Apply notch filters sequentially to remove noise at specified frequencies\n",
    "    traces_filtered = recording_art[i].get_traces()\n",
    "    for b, a in notch_filters:\n",
    "        traces_filtered = signal.filtfilt(b, a, traces_filtered, axis=0)\n",
    "\n",
    "    # Create a new RecordingExtractor with the filtered traces\n",
    "    recording_filtered = NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "    # Process LFP and MUA after filtering\n",
    "    lfp, mua = downsample_lfp_mua(recording_filtered)\n",
    "\n",
    "    # Apply filter bank to LFP\n",
    "    delta, s100_200, s200_400, gamma = filterbank(lfp)\n",
    "    recording_lfp.append(lfp)\n",
    "    recording_mua.append(mua)\n",
    "    recording_delta.append(delta)\n",
    "    recording_100_200.append(s100_200)\n",
    "    recording_200_400.append(s200_400)\n",
    "    recording_gamma.append(gamma)\n",
    "\n",
    "    # Resample artifact frames for further analysis\n",
    "    stim_frames = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames[i])))\n",
    "    artifact_frames_resample.append(stim_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import signal\n",
    "\n",
    "# # Function to plot PSD for all channels of a given recording\n",
    "# def plot_psd(recording, title, fs=1000):\n",
    "#     num_channels = recording.get_traces().shape[1]\n",
    "#     fig, axes = plt.subplots(1, num_channels, figsize=(15, 5))\n",
    "#     for ch in range(num_channels):\n",
    "#         # Extract channel data\n",
    "#         channel_data = recording.get_traces()[:, ch]\n",
    "#         # Compute PSD\n",
    "#         f, Pxx = signal.welch(channel_data, fs=fs, nperseg=fs*2)\n",
    "#         # Plot PSD\n",
    "#         axes[ch].semilogy(f, Pxx)\n",
    "#         axes[ch].set_xlim([1, 30])  # Limit frequency range\n",
    "        \n",
    "#         axes[ch].set_title(f'Channel {ch+1} PSD')\n",
    "#         axes[ch].set_xlabel('Frequency [Hz]')\n",
    "#         axes[ch].set_ylabel('PSD [V^2/Hz]')\n",
    "#         axes[ch].grid(True)\n",
    "#     plt.suptitle(title, fontsize=16)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Generate 21 PSD plots for recording 0-6 (each with 3 channels)\n",
    "# for i in range(7):\n",
    "#     plot_psd(recording_lfp[i], title=f'Recording {i}: PSD for 3 Channels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import numpy as np\n",
    "# # import scipy.signal as sp_signal  # Rename scipy.signal to avoid conflicts\n",
    "# # from spikeinterface.extractors import NumpyRecording\n",
    "# # import matplotlib.pyplot as plt\n",
    "# # import seaborn as sns\n",
    "# # from scipy.signal import hilbert \n",
    "\n",
    "# # Auxiliary function\n",
    "# def extract_phase(signal):\n",
    "#     \"\"\"Extract the instantaneous phase of a signal using the Hilbert transform\"\"\"\n",
    "#     analytic_signal = hilbert(signal)\n",
    "#     phase = np.angle(analytic_signal)\n",
    "#     return phase\n",
    "\n",
    "# def calculate_plv(phases):\n",
    "#     \"\"\"Compute the phase-locking value (PLV) between multiple signals\"\"\"\n",
    "#     n_signals = phases.shape[0]\n",
    "#     plv_matrix = np.zeros((n_signals, n_signals))\n",
    "#     for i in range(n_signals):\n",
    "#         for j in range(i + 1, n_signals):\n",
    "#             phase_diff = phases[i] - phases[j]\n",
    "#             plv_matrix[i, j] = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "#             plv_matrix[j, i] = plv_matrix[i, j]\n",
    "#     return plv_matrix\n",
    "\n",
    "# def bandpass_filter(signal, lowcut, highcut, fs, order=4):\n",
    "#     \"\"\"Band-pass filter\"\"\"\n",
    "#     nyquist = 0.5 * fs\n",
    "#     low = lowcut / nyquist\n",
    "#     high = highcut / nyquist\n",
    "#     b, a = sp_signal.butter(order, [low, high], btype=\"band\")\n",
    "#     filtered_signal = sp_signal.filtfilt(b, a, signal, axis=0)\n",
    "#     return filtered_signal\n",
    "\n",
    "# def calculate_band_plv(traces_filtered, fs, lowcut, highcut):\n",
    "#     \"\"\"Compute PLV for a specific frequency band\"\"\"\n",
    "#     band_filtered = np.array([bandpass_filter(traces_filtered[:, ch], lowcut, highcut, fs) for ch in range(traces_filtered.shape[1])])\n",
    "#     phases = np.array([extract_phase(band_filtered[ch]) for ch in range(band_filtered.shape[0])])\n",
    "#     plv_matrix = calculate_plv(phases)\n",
    "#     return plv_matrix\n",
    "\n",
    "# # Create Notch filters\n",
    "# frequencies_to_remove = [60]  # Frequencies to be removed\n",
    "# qs = [60]  # High-quality factor for narrow-band filtering\n",
    "# notch_filters = [sp_signal.iirnotch(f, q, 1000) for f, q in zip(frequencies_to_remove, qs)]\n",
    "\n",
    "# # Iterate over recordings\n",
    "# # for i in range(len(recording_art)):\n",
    "# for i in range(len([1, 2])):\n",
    "#     # Extract LFP signals\n",
    "#     lfp = recording_lfp[i].get_traces()\n",
    "#     start_time = 30  # Start time (seconds)\n",
    "#     end_time = start_time + 2  # End time (seconds)\n",
    "\n",
    "#     start_sample = int(start_time * fs)\n",
    "#     end_sample = int(end_time * fs)\n",
    "#     lfp = lfp[start_sample:end_sample, :]  # Extract the first 10 seconds of data\n",
    "#     fs = recording_lfp[i].get_sampling_frequency()\n",
    "\n",
    "#     # Step 1: Compute PLV for the original 5-20 Hz signal\n",
    "#     plv_5_20hz_original = calculate_band_plv(lfp, fs, 55, 65.0)\n",
    "#     print(f\"Recording {i}: Original PLV for 5-20 Hz:\\n{plv_5_20hz_original}\")\n",
    "\n",
    "#     # Step 2: Apply Notch filter to remove 9 Hz and 18 Hz\n",
    "#     lfp_notch_filtered = lfp.copy()\n",
    "#     for b, a in notch_filters:\n",
    "#         lfp_notch_filtered = sp_signal.filtfilt(b, a, lfp_notch_filtered, axis=0)\n",
    "\n",
    "#     # Step 3: Compute PLV for 5-20 Hz after Notch filtering\n",
    "#     plv_5_20hz_filtered = calculate_band_plv(lfp_notch_filtered, fs, 55.0, 65.0)\n",
    "#     print(f\"Recording {i}: PLV for 5-20 Hz after Notch Filtering:\\n{plv_5_20hz_filtered}\")\n",
    "\n",
    "#     # Visualize PLV matrix\n",
    "#     def visualize_plv(plv_matrix, title):\n",
    "#         plt.figure(figsize=(6, 4))\n",
    "#         sns.heatmap(plv_matrix, annot=True, cmap=\"viridis\", xticklabels=[\"Ch1\", \"Ch2\", \"Ch3\"], yticklabels=[\"Ch1\", \"Ch2\", \"Ch3\"])\n",
    "#         plt.title(title)\n",
    "#         plt.xlabel(\"Channels\")\n",
    "#         plt.ylabel(\"Channels\")\n",
    "#         plt.show()\n",
    "\n",
    "#     # Visualize the PLV matrices for the original and filtered signals\n",
    "#     visualize_plv(plv_5_20hz_original, f\"Original PLV for 5-20 Hz (Recording {i})\")\n",
    "#     visualize_plv(plv_5_20hz_filtered, f\"PLV for 5-20 Hz after Notch Filtering (Recording {i})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PLV\n",
    "# plv_5_10hz = calculate_band_plv(lfp, fs, 55, 58.0)\n",
    "# plv_10_20hz = calculate_band_plv(lfp, fs, 62, 65.0)\n",
    "# plv_5_10hz_filtered = calculate_band_plv(lfp_notch_filtered, fs, 55.0, 58.0)\n",
    "# plv_10_20hz_filtered = calculate_band_plv(lfp_notch_filtered, fs, 62.0, 65.0)\n",
    "\n",
    "# print(f\"Original PLV for 5-10 Hz:\\n{plv_5_10hz}\")\n",
    "# print(f\"Filtered PLV for 5-10 Hz:\\n{plv_5_10hz_filtered}\")\n",
    "# print(f\"Original PLV for 10-20 Hz:\\n{plv_10_20hz}\")\n",
    "# print(f\"Filtered PLV for 10-20 Hz:\\n{plv_10_20hz_filtered}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_frequency(recording, title, fs=1000):\n",
    "    \"\"\"\n",
    "    Function to plot time-frequency spectrograms for all channels of a given recording.\n",
    "    Args:\n",
    "    - recording: Recording object with `get_traces()` method.\n",
    "    - title: Title for the plots.\n",
    "    - fs: Sampling frequency of the recording (default is 30 kHz).\n",
    "    \"\"\"\n",
    "    num_channels = recording.get_traces().shape[1]\n",
    "    fig, axes = plt.subplots(1, num_channels, figsize=(15, 5))\n",
    "    for ch in range(num_channels):\n",
    "        # Extract channel data\n",
    "        channel_data = recording.get_traces()[:, ch]\n",
    "        # Compute and plot spectrogram\n",
    "        f, t, Sxx = signal.spectrogram(channel_data, fs=fs, nperseg=256, noverlap=128)\n",
    "        axes[ch].pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud')\n",
    "        axes[ch].set_ylim([1, 20])  # Limit frequency range for better visualization\n",
    "        axes[ch].set_title(f'Channel {ch+1}')\n",
    "        axes[ch].set_xlabel('Time [s]')\n",
    "        axes[ch].set_ylabel('Frequency [Hz]')\n",
    "        \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate 21 time-frequency spectrograms for recording 0-6 (each with 3 channels)\n",
    "for i in range(7):\n",
    "    plot_time_frequency(recording_lfp[i], title=f'Recording {i}: Time-Frequency for 3 Channels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft\n",
    "\n",
    "def plot_stft(recording, title, fs=1000):\n",
    "    \"\"\"\n",
    "    Function to plot STFT-based time-frequency spectrograms for all channels of a given recording.\n",
    "    Args:\n",
    "    - recording: Recording object with `get_traces()` method.\n",
    "    - title: Title for the plots.\n",
    "    - fs: Sampling frequency of the recording (default is 30 kHz).\n",
    "    \"\"\"\n",
    "    num_channels = recording.get_traces().shape[1]\n",
    "    fig, axes = plt.subplots(1, num_channels, figsize=(15, 5))\n",
    "    for ch in range(num_channels):\n",
    "        # Extract channel data\n",
    "        channel_data = recording.get_traces()[:, ch]\n",
    "        # Compute STFT\n",
    "        f, t, Zxx = stft(channel_data, fs=fs, nperseg=256, noverlap=128)\n",
    "        # Plot the spectrogram (magnitude of STFT)\n",
    "        axes[ch].pcolormesh(t, f, np.abs(Zxx), shading='gouraud')\n",
    "        axes[ch].set_ylim([1, 20])  # Limit frequency range for better visualization\n",
    "        axes[ch].set_xlim([5, 400])\n",
    "        axes[ch].set_title(f'Channel {ch+1}')\n",
    "        axes[ch].set_xlabel('Time [s]')\n",
    "        axes[ch].set_ylabel('Frequency [Hz]')\n",
    "        \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate 21 STFT spectrograms for recording 0-6 (each with 3 channels)\n",
    "for i in range(7):\n",
    "    plot_stft(recording_lfp[i], title=f'Recording {i}: STFT Time-Frequency for 3 Channels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 0  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[0].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[9000000]])\n",
    "    # axs[i].set_xlim([time_axis[6900000], time_axis[8000000]])\n",
    "    #axs[i].set_ylim([-0.000025, 0.000025])\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 0  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[0].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[300000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "nperseg = 5*fs_stim  # Window size for coherence calculation\n",
    "overlap = 0.5*nperseg\n",
    "fig, axs = plt.subplots(8, 3, sharex=True, sharey=True, dpi=400, figsize=(20, 30))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "time_buffer = 0.7 #seconds before/after stimulus, to avoid artifacts\n",
    "time_period = 2 #seconds\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "# Step 1: Calculate Pre-Stimulus Coherence (First 5 Minutes)\n",
    "stim_start_array_new = []\n",
    "\n",
    "for stim in stim_start_array:\n",
    "    stim_start1 = stim[0]  \n",
    "    stim_start_array_new.append(stim_start1)\n",
    "\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    segment = recording_lfp[i].get_traces()[5 * fs_stim : 255 * fs_stim, :]  \n",
    "    #segment = recording_lfp[i].get_traces()[int(stim_start_array_new[i]* fs_stim-time_period* fs_stim-time_buffer* fs_stim):int(stim_start_array_new[i]* fs_stim-time_buffer* fs_stim),:]\n",
    "\n",
    "  \n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "    # segment = recording_lfp[i].get_traces()[:200*fs_stim, :] \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pre-stimulus)')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 50])\n",
    "        axs[i, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg1 = coherence_sum / 7\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[7, j].semilogy(f, coherence_avg1[:, j])\n",
    "    axs[7, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[7, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[7, j].set_ylabel('Coherence')\n",
    "    axs[7, j].set_xlim([1, 20])\n",
    "    axs[7, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import signal\n",
    "\n",
    "# fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "# nperseg = 0.8*fs_stim  # Window size for coherence calculation\n",
    "# fig, axs = plt.subplots(8, 3, sharex=True, sharey=True, dpi=400, figsize=(20, 30))  # Six rows, three columns\n",
    "# titles = ['North-East', 'North-West', 'East-West']\n",
    "# ind1 = [0, 0, 1]\n",
    "# ind2 = [1, 2, 2]\n",
    "\n",
    "# coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "# # Step 1: Calculate Pre-Stimulus Coherence (First 5 Minutes)\n",
    "\n",
    "# # Step 2: Calculate Post-Stimulus Coherence (10 seconds before first stimulus, 4 seconds duration)\n",
    "# stim_start_array_old = []\n",
    "# stim_end_array_old = []\n",
    "# for stim in stim_times_array:\n",
    "#     stim_start = stim[0] - 10 \n",
    "#     stim_end = stim_start + 4 \n",
    "#     stim_start_array_old.append(stim_start)\n",
    "#     stim_end_array_old.append(stim_end)\n",
    "\n",
    "# snr_values = []  # Store SNR values for visualization\n",
    "\n",
    "# for i in range(len(recording_names)):\n",
    "#     segment = recording_lfp[i].get_traces()[int(stim_start_array_old[0]):int(stim_end_array_old[0]), :]\n",
    "    \n",
    "#     # Calculate SNR using RMS method\n",
    "#     signal_rms = np.sqrt(np.mean(segment**2, axis=0))\n",
    "#     noise_segment = recording_lfp[i].get_traces()[int(stim_start_array[0][0]):int(stim_start_array[0][0])+2, :]  # Take the first 5 seconds as baseline noise\n",
    "#     noise_rms = np.sqrt(np.mean(noise_segment**2, axis=0))\n",
    "#     snr_rms = 20 * np.log10(signal_rms / noise_rms)\n",
    "#     snr_values.append(snr_rms)\n",
    "    \n",
    "#     for j in range(3):\n",
    "#         x_post = segment[:, ind1[j]]\n",
    "#         y_post = segment[:, ind2[j]]\n",
    "#         f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg)\n",
    "        \n",
    "#         coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "#         axs[i, j].semilogy(f, Cxy_post)\n",
    "#         axs[i, j].set_title(f'{titles[j]} (Pre-stimulus)')\n",
    "#         axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "#         axs[i, j].set_ylabel('Coherence')\n",
    "#         axs[i, j].set_xlim([1, 400])\n",
    "#         axs[i, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "# # Calculate the average coherence\n",
    "# coherence_avg1 = coherence_sum / 7\n",
    "\n",
    "# # Plot the average coherence in the last row\n",
    "# for j in range(3):\n",
    "#     axs[7, j].semilogy(f, coherence_avg1[:, j])\n",
    "#     axs[7, j].set_title(f'{titles[j]} (Average)')\n",
    "#     axs[7, j].set_xlabel('Frequency [Hz]')\n",
    "#     axs[7, j].set_ylabel('Coherence')\n",
    "#     axs[7, j].set_xlim([1, 400])\n",
    "#     axs[7, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stim_start_array_old = []\n",
    "# stim_end_array_old = []\n",
    "# for stim in stim_times_array:\n",
    "#     stim_start = stim[0] - 10 \n",
    "#     stim_end = stim_start + 4 \n",
    "#     stim_start_array_old.append(stim_start)\n",
    "#     stim_end_array_old.append(stim_end)\n",
    "# stim_start_array_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot SNR values per channel for each recording\n",
    "# plt.figure(dpi=200, figsize=(10, 6))\n",
    "# snr_values_array = np.array(snr_values)\n",
    "# for ch in range(snr_values_array.shape[1]):\n",
    "#     plt.plot(snr_values_array[:, ch], label=f'Channel {ch+1}', marker='o')\n",
    "# plt.xlabel('Recording Index')\n",
    "# plt.ylabel('SNR (dB)')\n",
    "# plt.title('SNR of Different Channels Using RMS Method')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_names1 = ['BO11_O7W_Sti_Day4_5uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_10uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_20uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_30uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_40uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_50uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_60uA_m.nwb'\n",
    "                   ]\n",
    "\n",
    "amps1 = ['5ua','10ua','20ua',\n",
    "        '30ua','40ua','50ua','60ua']\n",
    "intan_path1 = 'C:/Users/27707/Documents/jhu_master/LFP_analysis/2024-07-26_DG_3elec/Experimental Set_Final Round_Batch 27/7 Week Old Organoid/Stimulation Day1/'\n",
    "intan_folders1 = ['5uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_5uA_240708_144920/merged/',\n",
    "                 '10uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_10uA_240708_145755/merged/',\n",
    "                 '20uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_20uA_240708_150743/merged/',\n",
    "                 '30uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_30uA_240708_151657/merged/',\n",
    "                 '40uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_40uA_240708_152646/merged/',\n",
    "                 '50uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_50uA_240708_153556/merged/',\n",
    "                 '60uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_60uA_240708_154509/merged/'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times_array1 = []\n",
    "for i in range(len(recording_names1)):\n",
    "    BO7_res1 = pull_files(intan_folders1[i], intan_path1)\n",
    "    stim_names_BO71 = ['STIM_A-000','STIM_A-002','STIM_A-004']\n",
    "    stim_BO71 = all_intan_data(stim_names_BO71,'stim_data',BO7_res1)\n",
    "    stim_times1 = stim_BO71.loc[(stim_BO71['STIM_A-000'] != 0) | (stim_BO71['STIM_A-002'] != 0) | (stim_BO71['STIM_A-004'] != 0)].index\n",
    "    stim_times_array1.append(stim_times1.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_start_array1 = []\n",
    "stim_end_array1 = []\n",
    "for stim in stim_times_array1:\n",
    "    stim = np.insert(stim,0,0)\n",
    "    stim_times_diff1 = np.diff(stim)\n",
    "    stim_start1 = stim[np.where(stim_times_diff1 > 1)[0]+1]\n",
    "    stim_end1 = stim[np.where(stim_times_diff1 > 1)[0][1:]]\n",
    "    stim_end1 = np.concatenate((stim_end1,[stim[-1]]))\n",
    "    print(stim_start1)\n",
    "    print(stim_end1)\n",
    "    stim_start_array1.append(stim_start1)\n",
    "    stim_end_array1.append(stim_end1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples1 = []\n",
    "num_channels1 = []\n",
    "multirecording1 = []\n",
    "multirecording_f1 = []\n",
    "for i in range(len(recording_names1)):\n",
    "    recording_names1 = [folder + 'BO11_O7W_Sti_Day4_' + amp.split('u')[0] + 'uA_m.nwb' \n",
    "                       for folder, amp in zip(intan_folders1, amps1)]\n",
    "    rec_names1 = intan_path1 + recording_names1[i]\n",
    "    day_recording1 = load_data(rec_names1)\n",
    "    [num_pre_samples1, num_pre_channels1] = day_recording1.get_traces().shape # Num samples, num channels\n",
    "    num_samples1.append(num_pre_samples1)\n",
    "    num_channels1.append(num_pre_channels1)\n",
    "    print('Presample:' + str(num_pre_samples1))\n",
    "\n",
    "    # Case 2: the sorter DOES NOT handle multi-segment objects\n",
    "    multirecording_1 = day_recording1 # The `concatenate_recordings()` mimics a mono-segment object that concatenates all segments\n",
    "    multirecording1.append(day_recording1) # load your recording using SpikeInterface\n",
    "    multi_shank1 = gen_probe()\n",
    "    multirecording_filter1 = spre.bandpass_filter(multirecording1[i], freq_min=300, freq_max=6000)\n",
    "    multirecording_f1.append(multirecording_filter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_before = [100]\n",
    "ms_after = [100]\n",
    "\n",
    "\n",
    "# Step 1: Calculate RMS-based thresholds for each recording and channel\n",
    "fs = 30000  # Replace with your actual sampling rate\n",
    "start_time = 5  # Start at 10 seconds\n",
    "end_time = 255  # End at 210 seconds\n",
    "num_samples = fs * (end_time - start_time)  # Calculate the number of samples for 200 seconds\n",
    "\n",
    "thresholds1 = []  # Initialize an empty list to store thresholds for each recording\n",
    "\n",
    "for i in range(len(recording_names1)):\n",
    "    thresholds_per_recording1 = []  # Store thresholds for each channel in the current recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        # Extract the channel data from the 10th second to the 210th second of signal\n",
    "        channel1 = multirecording1[i].get_traces()[start_time * fs:end_time * fs, ch].astype(np.float32)\n",
    "\n",
    "        # Calculate the RMS value and determine the threshold\n",
    "        rms_value = np.sqrt(np.mean(channel1**2))\n",
    "        threshold = rms_value * 5.0\n",
    "        thresholds_per_recording1.append(threshold)\n",
    "    \n",
    "    thresholds1.append(thresholds_per_recording1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_frames1 = []\n",
    "for i in range(len(recording_names1)):\n",
    "    artifact_frames_per_recording1 = []  # Store artifact frames for each channel in a recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        channel1 = multirecording1[i].get_traces()[:, ch].astype(np.float32)\n",
    "        #plt.figure()\n",
    "        #plt.plot(channel)\n",
    "        \n",
    "        # Use predefined threshold for the current recording and channel\n",
    "        threshold1 = thresholds1[i][ch]\n",
    "        print(f\"Threshold for recording {i+1}, channel {ch+1}: {threshold1}\")\n",
    "        \n",
    "        # Apply the custom threshold\n",
    "        stimulation_trigger_frames1 = np.where(np.abs(channel1) > threshold1)\n",
    "        \n",
    "        # Remove artifacts using the detected triggers\n",
    "        multirecording_art1 = spre.remove_artifacts(\n",
    "            multirecording1[i],\n",
    "            list_triggers=stimulation_trigger_frames1[0].tolist(),\n",
    "            ms_before=ms_before[0],  \n",
    "            ms_after=ms_after[0]\n",
    "        )\n",
    "        \n",
    "        artifact_frames_per_recording1.append(stimulation_trigger_frames1[0].tolist())\n",
    "        #plt.plot(multirecording_art.get_traces()[:, ch])  # Ensure the recording is preprocessed appropriately\n",
    "        #plt.show()\n",
    "    \n",
    "    artifact_frames1.append(artifact_frames_per_recording1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import numpy as np\n",
    "\n",
    "recording_art1 = []\n",
    "recording_lfp1 = []\n",
    "recording_mua1= []\n",
    "recording_delta1 = []\n",
    "recording_100_2001 = []\n",
    "recording_200_4001 = []\n",
    "recording_gamma1 = []\n",
    "artifact_frames_resample1 = []\n",
    "\n",
    "# Create notch filters for specific frequencies\n",
    "#frequencies = [ 9.0, 18.2, 25.0, 27.2, 29.2, 36.4, 37.6, 41.4, 43.8, 45.4, 46.4, 60.0, 180.0, 300.0]\n",
    "frequencies = [60.0, 180.0, 300.0]\n",
    "qs = [60, 180, 300]  \n",
    "notch_filters = [signal.iirnotch(f, q, 30000) for f, q in zip(frequencies, qs)]\n",
    "\n",
    "for i in range(len(recording_names1)):\n",
    "    rc1 = []\n",
    "    for ch in range(3):\n",
    "        # Remove artifacts for each channel\n",
    "        recording_artifact_removed1 = spre.remove_artifacts(\n",
    "            multirecording1[i],\n",
    "            list_triggers=artifact_frames1[i][ch],  # Combine triggers from all channels\n",
    "            ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "        )\n",
    "        channel_data_artifact_removed1 = recording_artifact_removed1.get_traces()[:, ch]\n",
    "\n",
    "        # Append the artifact-removed channel data to rc list\n",
    "        rc1.append(channel_data_artifact_removed1)\n",
    "\n",
    "    # Combine the channels into one array\n",
    "    combined_data1 = np.stack(rc1, axis=1)  # Stack along the channel axis\n",
    "\n",
    "    # Create a new RecordingExtractor object with combined data\n",
    "    sampling_frequency = multirecording1[i].get_sampling_frequency()\n",
    "    combined_recording1 = NumpyRecording(traces_list=[combined_data1], sampling_frequency=sampling_frequency)\n",
    "\n",
    "    # Append the filtered recording to the list\n",
    "    recording_art1.append(combined_recording1)\n",
    "\n",
    "    # Apply notch filters sequentially to remove noise at specified frequencies\n",
    "    traces_filtered = recording_art1[i].get_traces()\n",
    "    for b, a in notch_filters:\n",
    "        traces_filtered = signal.filtfilt(b, a, traces_filtered, axis=0)\n",
    "\n",
    "    # Create a new RecordingExtractor with the filtered traces\n",
    "    recording_filtered1 = NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "    # Process LFP and MUA after filtering\n",
    "    lfp1, mua1 = downsample_lfp_mua(recording_filtered1)\n",
    "\n",
    "    # Apply filter bank to LFP\n",
    "    delta1, s100_2001, s200_4001, gamma1 = filterbank(lfp)\n",
    "    recording_lfp1.append(lfp1)\n",
    "    recording_mua1.append(mua1)\n",
    "    recording_delta1.append(delta1)\n",
    "    recording_100_2001.append(s100_2001)\n",
    "    recording_200_4001.append(s200_4001)\n",
    "    recording_gamma1.append(gamma1)\n",
    "\n",
    "    # Resample artifact frames for further analysis\n",
    "    stim_frames1 = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames1[i])))\n",
    "    artifact_frames_resample1.append(stim_frames1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs1 = 30000  # Sampling frequency (30kHz)\n",
    "time_window1 = 0  # 5 minutes in seconds\n",
    "start_sample1 = int(time_window1 * fs1)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post1 = recording_art1[2].get_traces()[start_sample1:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis1 = np.arange(start_sample1, start_sample1 + raw_data_post1.shape[0]) / fs1\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels1 = raw_data_post1.shape[1]\n",
    "fig1, axs1 = plt.subplots(num_channels1, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels1):\n",
    "    axs1[i].plot(time_axis1, raw_data_post1[:, i])\n",
    "    axs1[i].set_title(f'Channel {i+1}')\n",
    "    axs1[i].set_ylabel('Amplitude (V)')\n",
    "    axs1[i].set_xlim([time_axis1[0], time_axis1[9000000]])\n",
    "    # axs[i].set_xlim([time_axis[6900000], time_axis[8000000]])\n",
    "    #axs1[i].set_ylim([-0.000025, 0.000025])\n",
    "axs1[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes1 = np.mean(np.abs(raw_data_post1), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes1):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set the parameters\n",
    "# fs1 = 1000  # Sampling frequency (30kHz)\n",
    "# time_window1 = 0  # 5 minutes in seconds\n",
    "# start_sample1 = int(time_window1 * fs1)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# # Extract the data from 5 minutes to the end\n",
    "# raw_data_post1 = recording_lfp1[2].get_traces()[start_sample1:, :]\n",
    "\n",
    "# # Calculate the time axis for the plot\n",
    "# time_axis1 = np.arange(start_sample1, start_sample1 + raw_data_post1.shape[0]) / fs1\n",
    "\n",
    "# # Plot the raw signal for each channel\n",
    "# num_channels1 = raw_data_post1.shape[1]\n",
    "# fig1, axs1 = plt.subplots(num_channels1, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "# for i in range(num_channels1):\n",
    "#     axs1[i].plot(time_axis1, raw_data_post1[:, i])\n",
    "#     axs1[i].set_title(f'Channel {i+1}')\n",
    "#     axs1[i].set_ylabel('Amplitude (V)')\n",
    "#     #axs1[i].set_xlim([time_axis1[135000], time_axis1[145000]])\n",
    "#     axs1[i].set_xlim([time_axis1[0], time_axis1[300000]])\n",
    "# axs1[-1].set_xlabel('Time (s)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate and print the average amplitude for each channel\n",
    "# average_amplitudes1 = np.mean(np.abs(raw_data_post1), axis=0)\n",
    "# for i, avg_amp in enumerate(average_amplitudes1):\n",
    "#     print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim1 = 1000  # Sampling frequency for stimulus data\n",
    "nperseg1 = 5*fs_stim1  # Window size for coherence calculation\n",
    "overlap = 0.2*nperseg1\n",
    "fig1, axs1 = plt.subplots(8, 3, sharex=True, sharey=True, dpi=400, figsize=(20, 30))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum1 = np.zeros((int(nperseg1/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "# Step 1: Calculate Pre-Stimulus Coherence (First 5 Minutes)\n",
    "\n",
    "stim_start_array_new1 = []\n",
    "\n",
    "for stim in stim_start_array1:\n",
    "    stim_start1 = stim[0]  \n",
    "    stim_start_array_new1.append(stim_start1)\n",
    "\n",
    "\n",
    "for i in range(len(recording_names1)):\n",
    "    segment1 = recording_lfp1[i].get_traces()[5 * fs_stim1 : 255 * fs_stim1, :]  \n",
    "    #segment1 = recording_lfp1[i].get_traces()[int(stim_start_array_new1[i]* fs_stim1-time_period* fs_stim1-time_buffer* fs_stim1):int(stim_start_array_new1[i]* fs_stim1-time_buffer* fs_stim1),:]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post1 = segment1[:, ind1[j]]\n",
    "        y_post1 = segment1[:, ind2[j]]\n",
    "        f_1, Cxy_post1 = signal.coherence(x_post1, y_post1, fs_stim1, nperseg=nperseg1,noverlap=overlap)\n",
    "        \n",
    "        coherence_sum1[:, j] += Cxy_post1  # Accumulate coherence values\n",
    "        \n",
    "        axs1[i, j].semilogy(f_1, Cxy_post1)\n",
    "        axs1[i, j].set_title(f'{titles[j]} (Pre-stimulus)')\n",
    "        axs1[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs1[i, j].set_ylabel('Coherence')\n",
    "        axs1[i, j].set_xlim([1, 50])\n",
    "        axs1[i, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg2 = coherence_sum1 / 7\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs1[7, j].semilogy(f_1, coherence_avg2[:, j])\n",
    "    axs1[7, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs1[7, j].set_xlabel('Frequency [Hz]')\n",
    "    axs1[7, j].set_ylabel('Coherence')\n",
    "    axs1[7, j].set_xlim([1, 50])\n",
    "    axs1[7, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_names = ['BO5_O7W_Sti_Day4_5uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_10uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_20uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_30uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_40uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_50uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_60uA_m.nwb'\n",
    "                   ]\n",
    "\n",
    "amps = ['5ua','10ua','20ua',\n",
    "        '30ua','40ua','50ua','60ua']\n",
    "intan_path = 'C:/Users/27707/Documents/jhu_master/LFP_analysis/2024-07-26_DG_3elec/Experimental Set_Final Round_Batch 27/7 Week Old Organoid/Stimulation Day1/'\n",
    "intan_folders = ['5uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_5uA_240708_122554/merged/',\n",
    "                 '10uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_10uA_240708_123516/merged/',\n",
    "                 '20uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_20uA_240708_124435/merged/',\n",
    "                 '30uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_30uA_240708_125400/merged/',\n",
    "                 '40uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_40uA_240708_130304/merged/',\n",
    "                 '50uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_50uA_240708_131207/merged/',\n",
    "                 '60uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_60uA_240708_132110/merged/'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times_array = []\n",
    "for i in range(len(recording_names)):\n",
    "    BO7_res = pull_files(intan_folders[i], intan_path)\n",
    "    stim_names_BO7 = ['STIM_A-000','STIM_A-002','STIM_A-004']\n",
    "    stim_BO7 = all_intan_data(stim_names_BO7,'stim_data',BO7_res)\n",
    "    stim_times = stim_BO7.loc[(stim_BO7['STIM_A-000'] != 0) | (stim_BO7['STIM_A-002'] != 0) | (stim_BO7['STIM_A-004'] != 0)].index\n",
    "    stim_times_array.append(stim_times.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_start_array = []\n",
    "stim_end_array = []\n",
    "for stim in stim_times_array:\n",
    "    stim = np.insert(stim,0,0)\n",
    "    stim_times_diff = np.diff(stim)\n",
    "    stim_start = stim[np.where(stim_times_diff > 1)[0]+1]\n",
    "    stim_end = stim[np.where(stim_times_diff > 1)[0][1:]]\n",
    "    stim_end = np.concatenate((stim_end,[stim[-1]]))\n",
    "    print(stim_start)\n",
    "    print(stim_end)\n",
    "    stim_start_array.append(stim_start)\n",
    "    stim_end_array.append(stim_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = []\n",
    "num_channels = []\n",
    "multirecording = []\n",
    "multirecording_f = []\n",
    "for i in range(len(recording_names)):\n",
    "    recording_names = [folder + 'BO5_O7W_Sti_Day4_' + amp.split('u')[0] + 'uA_240708_m.nwb' \n",
    "                       for folder, amp in zip(intan_folders, amps)]\n",
    "    rec_names = intan_path + recording_names[i]\n",
    "    day_recording = load_data(rec_names)\n",
    "    [num_pre_samples, num_pre_channels] = day_recording.get_traces().shape # Num samples, num channels\n",
    "    num_samples.append(num_pre_samples)\n",
    "    num_channels.append(num_pre_channels)\n",
    "    print('Presample:' + str(num_pre_samples))\n",
    "\n",
    "    # Case 2: the sorter DOES NOT handle multi-segment objects\n",
    "    multirecording_1 = day_recording # The `concatenate_recordings()` mimics a mono-segment object that concatenates all segments\n",
    "    multirecording.append(day_recording) # load your recording using SpikeInterface\n",
    "    multi_shank = gen_probe()\n",
    "    multirecording_filter = spre.bandpass_filter(multirecording[i], freq_min=300, freq_max=6000)\n",
    "    multirecording_f.append(multirecording_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Calculate RMS-based thresholds for each recording and channel\n",
    "fs = 30000  # Replace with your actual sampling rate\n",
    "start_time = 5  # Start at 10 seconds\n",
    "end_time = 255  # End at 210 seconds\n",
    "num_samples = fs * (end_time - start_time)  # Calculate the number of samples for 200 seconds\n",
    "\n",
    "thresholds = []  # Initialize an empty list to store thresholds for each recording\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    thresholds_per_recording = []  # Store thresholds for each channel in the current recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        # Extract the channel data from the 10th second to the 210th second of signal\n",
    "        channel = multirecording[i].get_traces()[start_time * fs:end_time * fs, ch].astype(np.float32)\n",
    "\n",
    "        # Calculate the RMS value and determine the threshold\n",
    "        rms_value = np.sqrt(np.mean(channel**2))\n",
    "        threshold = rms_value * 5.0\n",
    "        thresholds_per_recording.append(threshold)\n",
    "    \n",
    "    thresholds.append(thresholds_per_recording)\n",
    "\n",
    "# Now, use the thresholds in the original artifact detection code\n",
    "ms_before = [100]\n",
    "ms_after = [100]\n",
    "artifact_frames = []\n",
    "\n",
    "# Original loop for artifact detection\n",
    "for i in range(len(recording_names)):\n",
    "    artifact_frames_per_recording = []  # Store artifact frames for each channel in a recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        channel = multirecording[i].get_traces()[:, ch].astype(np.float32)\n",
    "        \n",
    "        # Use predefined threshold for the current recording and channel\n",
    "        threshold = thresholds[i][ch]\n",
    "        print(f\"Threshold for recording {i+1}, channel {ch+1}: {threshold}\")\n",
    "        \n",
    "        # Apply the custom threshold\n",
    "        stimulation_trigger_frames = np.where(np.abs(channel) > threshold)\n",
    "\n",
    "        # Remove artifacts using the detected triggers\n",
    "        if stimulation_trigger_frames[0].size > 0:  # Check if there are any detected triggers\n",
    "            multirecording_art = spre.remove_artifacts(\n",
    "                multirecording[i],\n",
    "                list_triggers=stimulation_trigger_frames[0].tolist(),\n",
    "                ms_before=ms_before[0],  \n",
    "                ms_after=ms_after[0]\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No artifacts detected for recording {i+1}, channel {ch+1}\")\n",
    "        \n",
    "        artifact_frames_per_recording.append(stimulation_trigger_frames[0].tolist())\n",
    "\n",
    "    artifact_frames.append(artifact_frames_per_recording)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import numpy as np\n",
    "\n",
    "recording_art = []\n",
    "recording_lfp = []\n",
    "recording_mua = []\n",
    "recording_delta = []\n",
    "recording_100_200 = []\n",
    "recording_200_400 = []\n",
    "recording_gamma = []\n",
    "artifact_frames_resample = []\n",
    "\n",
    "# Create notch filters for specific frequencies\n",
    "#frequencies = [ 9.0, 18.2, 25.0, 27.2, 29.2, 36.4, 37.6, 41.4, 43.8, 45.4, 46.4, 60.0, 180.0, 300.0]\n",
    "frequencies = [60.0, 180.0, 300.0]\n",
    "qs = [60, 180, 300]  \n",
    "notch_filters = [signal.iirnotch(f, q, 30000) for f, q in zip(frequencies, qs)]\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    rc = []\n",
    "    for ch in range(3):\n",
    "        # Remove artifacts for each channel\n",
    "        recording_artifact_removed = spre.remove_artifacts(\n",
    "            multirecording[i],\n",
    "            list_triggers=artifact_frames[i][ch],  # Combine triggers from all channels\n",
    "            ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "        )\n",
    "        channel_data_artifact_removed = recording_artifact_removed.get_traces()[:, ch]\n",
    "\n",
    "        # Append the artifact-removed channel data to rc list\n",
    "        rc.append(channel_data_artifact_removed)\n",
    "\n",
    "    # Combine the channels into one array\n",
    "    combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "    # Create a new RecordingExtractor object with combined data\n",
    "    sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "    combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "\n",
    "    # Append the filtered recording to the list\n",
    "    recording_art.append(combined_recording)\n",
    "\n",
    "    # Apply notch filters sequentially to remove noise at specified frequencies\n",
    "    traces_filtered = recording_art[i].get_traces()\n",
    "    for b, a in notch_filters:\n",
    "        traces_filtered = signal.filtfilt(b, a, traces_filtered, axis=0)\n",
    "\n",
    "    # Create a new RecordingExtractor with the filtered traces\n",
    "    recording_filtered = NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "    # Process LFP and MUA after filtering\n",
    "    lfp, mua = downsample_lfp_mua(recording_filtered)\n",
    "\n",
    "    # Apply filter bank to LFP\n",
    "    delta, s100_200, s200_400, gamma = filterbank(lfp)\n",
    "    recording_lfp.append(lfp)\n",
    "    recording_mua.append(mua)\n",
    "    recording_delta.append(delta)\n",
    "    recording_100_200.append(s100_200)\n",
    "    recording_200_400.append(s200_400)\n",
    "    recording_gamma.append(gamma)\n",
    "\n",
    "    # Resample artifact frames for further analysis\n",
    "    stim_frames = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames[i])))\n",
    "    artifact_frames_resample.append(stim_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 0  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[0].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[9000000]])\n",
    "    # axs[i].set_xlim([time_axis[6900000], time_axis[8000000]])\n",
    "    #axs[i].set_ylim([-0.000025, 0.000025])\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set the parameters\n",
    "# fs = 1000  # Sampling frequency (30kHz)\n",
    "# time_window = 0  # 5 minutes in seconds\n",
    "# start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# # Extract the data from 5 minutes to the end\n",
    "# raw_data_post = recording_lfp[0].get_traces()[start_sample:, :]\n",
    "\n",
    "# # Calculate the time axis for the plot\n",
    "# time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# # Plot the raw signal for each channel\n",
    "# num_channels = raw_data_post.shape[1]\n",
    "# fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "# for i in range(num_channels):\n",
    "#     axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "#     axs[i].set_title(f'Channel {i+1}')\n",
    "#     axs[i].set_ylabel('Amplitude (V)')\n",
    "#     axs[i].set_xlim([time_axis[0], time_axis[300000]])\n",
    "\n",
    "# axs[-1].set_xlabel('Time (s)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate and print the average amplitude for each channel\n",
    "# average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "# for i, avg_amp in enumerate(average_amplitudes):\n",
    "#     print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "nperseg = 5*fs_stim  # Window size for coherence calculation\n",
    "overlap = 0.2*nperseg\n",
    "fig, axs = plt.subplots(8, 3, sharex=True, sharey=True, dpi=400, figsize=(20, 30))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "# Step 1: Calculate Pre-Stimulus Coherence (First 5 Minutes)\n",
    "\n",
    "stim_start_array_new = []\n",
    "\n",
    "for stim in stim_start_array:\n",
    "    stim_start1 = stim[0]  \n",
    "    stim_start_array_new.append(stim_start1)\n",
    "\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    segment = recording_lfp[i].get_traces()[5 * fs_stim : 255 * fs_stim, :]  \n",
    "    #segment = recording_lfp[i].get_traces()[int(stim_start_array_new[i]* fs_stim-time_period* fs_stim-time_buffer* fs_stim):int(stim_start_array_new[i]* fs_stim-time_buffer* fs_stim),:]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg,noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pre-stimulus)')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 50])\n",
    "        axs[i, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg3 = coherence_sum / 7\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[7, j].semilogy(f, coherence_avg3[:, j])\n",
    "    axs[7, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[7, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[7, j].set_ylabel('Coherence')\n",
    "    axs[7, j].set_xlim([1, 50])\n",
    "    axs[7, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_names = ['BO11_O5W_Sti_Day1_5uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_10uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_20uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_30uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_40uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_50uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_60uA_m.nwb'\n",
    "                   ]\n",
    "\n",
    "amps = ['5ua','10ua','20ua',\n",
    "        '30ua','40ua','50ua','60ua']\n",
    "intan_path = 'C:/Users/27707/Documents/jhu_master/LFP_analysis/2024-07-26_DG_3elec/Experimental Set_Final Round_Batch 27/5 Week Old Organoid/Stimulation Day1/'\n",
    "intan_folders = ['5uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_5uA_233uS_240625_123952/merged/',\n",
    "                 '10uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_10uA_233uS_240625_125131/merged/',\n",
    "                 '20uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_20uA_233uS_240625_130048/merged/',\n",
    "                 '30uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_30uA_233uS_240625_130939/merged/',\n",
    "                 '40uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_40uA_233uS_240625_131833/merged/',\n",
    "                 '50uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_50uA_233uS_240625_132735/merged/',\n",
    "                 '60uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_60uA_233uS_240625_133646/merged/'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times_array = []\n",
    "for i in range(len(recording_names)):\n",
    "    BO7_res = pull_files(intan_folders[i], intan_path)\n",
    "    stim_names_BO7 = ['STIM_A-000','STIM_A-002','STIM_A-004']\n",
    "    stim_BO7 = all_intan_data(stim_names_BO7,'stim_data',BO7_res)\n",
    "    stim_times = stim_BO7.loc[(stim_BO7['STIM_A-000'] != 0) | (stim_BO7['STIM_A-002'] != 0) | (stim_BO7['STIM_A-004'] != 0)].index\n",
    "    stim_times_array.append(stim_times.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_start_array = []\n",
    "stim_end_array = []\n",
    "for stim in stim_times_array:\n",
    "    stim = np.insert(stim,0,0)\n",
    "    stim_times_diff = np.diff(stim)\n",
    "    stim_start = stim[np.where(stim_times_diff > 1)[0]+1]\n",
    "    stim_end = stim[np.where(stim_times_diff > 1)[0][1:]]\n",
    "    stim_end = np.concatenate((stim_end,[stim[-1]]))\n",
    "    print(stim_start)\n",
    "    print(stim_end)\n",
    "    stim_start_array.append(stim_start)\n",
    "    stim_end_array.append(stim_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = []\n",
    "num_channels = []\n",
    "multirecording = []\n",
    "multirecording_f = []\n",
    "for i in range(len(recording_names)):\n",
    "    recording_names = [folder + 'BO11_O5W_Sti_Day1_' + amp.split('u')[0] + 'uA_m.nwb'\n",
    "                       for folder, amp in zip(intan_folders, amps)]\n",
    "    rec_names = intan_path + recording_names[i]\n",
    "    day_recording = load_data(rec_names)\n",
    "    [num_pre_samples, num_pre_channels] = day_recording.get_traces().shape # Num samples, num channels\n",
    "    num_samples.append(num_pre_samples)\n",
    "    num_channels.append(num_pre_channels)\n",
    "    print('Presample:' + str(num_pre_samples))\n",
    "\n",
    "    # Case 2: the sorter DOES NOT handle multi-segment objects\n",
    "    multirecording_1 = day_recording # The `concatenate_recordings()` mimics a mono-segment object that concatenates all segments\n",
    "    multirecording.append(day_recording) # load your recording using SpikeInterface\n",
    "    multi_shank = gen_probe()\n",
    "    multirecording_filter = spre.bandpass_filter(multirecording[i], freq_min=300, freq_max=6000)\n",
    "    multirecording_f.append(multirecording_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Calculate RMS-based thresholds for each recording and channel\n",
    "fs = 30000  # Replace with your actual sampling rate\n",
    "start_time = 5  # Start at 10 seconds\n",
    "end_time = 255  # End at 210 seconds\n",
    "num_samples = fs * (end_time - start_time)  # Calculate the number of samples for 200 seconds\n",
    "\n",
    "thresholds = []  # Initialize an empty list to store thresholds for each recording\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    thresholds_per_recording = []  # Store thresholds for each channel in the current recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        # Extract the channel data from the 10th second to the 210th second of signal\n",
    "        channel = multirecording[i].get_traces()[start_time * fs:end_time * fs, ch].astype(np.float32)\n",
    "\n",
    "        # Calculate the RMS value and determine the threshold\n",
    "        rms_value = np.sqrt(np.mean(channel**2))\n",
    "        threshold = rms_value * 5.2\n",
    "        thresholds_per_recording.append(threshold)\n",
    "    \n",
    "    thresholds.append(thresholds_per_recording)\n",
    "\n",
    "# Now, use the thresholds in the original artifact detection code\n",
    "ms_before = [100]\n",
    "ms_after = [100]\n",
    "artifact_frames = []\n",
    "\n",
    "# Original loop for artifact detection\n",
    "for i in range(len(recording_names)):\n",
    "    artifact_frames_per_recording = []  # Store artifact frames for each channel in a recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        channel = multirecording[i].get_traces()[:, ch].astype(np.float32)\n",
    "        \n",
    "        # Use predefined threshold for the current recording and channel\n",
    "        threshold = thresholds[i][ch]\n",
    "        print(f\"Threshold for recording {i+1}, channel {ch+1}: {threshold}\")\n",
    "        \n",
    "        # Apply the custom threshold\n",
    "        stimulation_trigger_frames = np.where(np.abs(channel) > threshold)\n",
    "\n",
    "        # Remove artifacts using the detected triggers\n",
    "        if stimulation_trigger_frames[0].size > 0:  # Check if there are any detected triggers\n",
    "            multirecording_art = spre.remove_artifacts(\n",
    "                multirecording[i],\n",
    "                list_triggers=stimulation_trigger_frames[0].tolist(),\n",
    "                ms_before=ms_before[0],  \n",
    "                ms_after=ms_after[0]\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No artifacts detected for recording {i+1}, channel {ch+1}\")\n",
    "        \n",
    "        artifact_frames_per_recording.append(stimulation_trigger_frames[0].tolist())\n",
    "\n",
    "    artifact_frames.append(artifact_frames_per_recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import numpy as np\n",
    "\n",
    "recording_art = []\n",
    "recording_lfp = []\n",
    "recording_mua = []\n",
    "recording_delta = []\n",
    "recording_100_200 = []\n",
    "recording_200_400 = []\n",
    "recording_gamma = []\n",
    "artifact_frames_resample = []\n",
    "\n",
    "# Create notch filters for specific frequencies\n",
    "#frequencies = [9.0, 18.2, 25.0, 27.2, 29.2, 36.4, 37.6, 41.4, 43.8, 45.4, 46.4, 60.0, 180.0, 300.0]\n",
    "frequencies = [60.0, 180.0, 300.0]\n",
    "qs = [60, 180, 300]  \n",
    "notch_filters = [signal.iirnotch(f, q, 30000) for f, q in zip(frequencies, qs)]\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    rc = []\n",
    "    for ch in range(3):\n",
    "        # Remove artifacts for each channel\n",
    "        recording_artifact_removed = spre.remove_artifacts(\n",
    "            multirecording[i],\n",
    "            list_triggers=artifact_frames[i][ch],  # Combine triggers from all channels\n",
    "            ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "        )\n",
    "        channel_data_artifact_removed = recording_artifact_removed.get_traces()[:, ch]\n",
    "\n",
    "        # Append the artifact-removed channel data to rc list\n",
    "        rc.append(channel_data_artifact_removed)\n",
    "\n",
    "    # Combine the channels into one array\n",
    "    combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "    # Create a new RecordingExtractor object with combined data\n",
    "    sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "    combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "\n",
    "    # Append the filtered recording to the list\n",
    "    recording_art.append(combined_recording)\n",
    "\n",
    "    # Apply notch filters sequentially to remove noise at specified frequencies\n",
    "    traces_filtered = recording_art[i].get_traces()\n",
    "    for b, a in notch_filters:\n",
    "        traces_filtered = signal.filtfilt(b, a, traces_filtered, axis=0)\n",
    "\n",
    "    # Create a new RecordingExtractor with the filtered traces\n",
    "    recording_filtered = NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "    # Process LFP and MUA after filtering\n",
    "    lfp, mua = downsample_lfp_mua(recording_filtered)\n",
    "\n",
    "    # Apply filter bank to LFP\n",
    "    delta, s100_200, s200_400, gamma = filterbank(lfp)\n",
    "    recording_lfp.append(lfp)\n",
    "    recording_mua.append(mua)\n",
    "    recording_delta.append(delta)\n",
    "    recording_100_200.append(s100_200)\n",
    "    recording_200_400.append(s200_400)\n",
    "    recording_gamma.append(gamma)\n",
    "\n",
    "    # Resample artifact frames for further analysis\n",
    "    stim_frames = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames[i])))\n",
    "    artifact_frames_resample.append(stim_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 0  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[6].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[9000000]])\n",
    "    # axs[i].set_xlim([time_axis[6900000], time_axis[8000000]])\n",
    "    #axs[i].set_ylim([-0.000025, 0.000025])\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 0  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[6].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[300000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "nperseg = 5*fs_stim  # Window size for coherence calculation\n",
    "fig, axs = plt.subplots(8, 3, sharex=True, sharey=True, dpi=400, figsize=(20, 30))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "# Step 1: Calculate Pre-Stimulus Coherence (First 5 Minutes)\n",
    "\n",
    "stim_start_array_new = []\n",
    "\n",
    "for stim in stim_start_array:\n",
    "    stim_start1 = stim[0]  \n",
    "    stim_start_array_new.append(stim_start1)\n",
    "\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    segment = recording_lfp[i].get_traces()[5 * fs_stim : 255 * fs_stim, :]  \n",
    "    #segment = recording_lfp[i].get_traces()[int(stim_start_array_new[i]* fs_stim-time_period* fs_stim-time_buffer* fs_stim):int(stim_start_array_new[i]* fs_stim-time_buffer* fs_stim),:]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg,noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pre-stimulus)')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 50])\n",
    "        axs[i, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg4 = coherence_sum / 7\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[7, j].semilogy(f, coherence_avg4[:, j])\n",
    "    axs[7, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[7, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[7, j].set_ylabel('Coherence')\n",
    "    axs[7, j].set_xlim([1, 50])\n",
    "    axs[7, j].set_ylim([10**(-5), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the average coherence across the four datasets\n",
    "average_coherence = (coherence_avg1  + coherence_avg2 + coherence_avg3 + coherence_avg4) / 4\n",
    "\n",
    "# Plot the average coherence result\n",
    "fig, axs = plt.subplots(1, 3, figsize=(30, 5), dpi=400)\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "\n",
    "for j in range(3):\n",
    "    axs[j].semilogy(f, average_coherence[:, j])\n",
    "    axs[j].set_title(f'{titles[j]}', fontsize=38)\n",
    "    axs[j].set_xlabel('Frequency [Hz]', fontsize=30)\n",
    "    axs[j].set_ylabel('Coherence', fontsize=30)\n",
    "    axs[j].tick_params(axis='both', which='major', labelsize=28)\n",
    "    axs[j].set_xlim([1, 49])\n",
    "    axs[j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the average coherence\n",
    "average_coherence = (coherence_avg1 + coherence_avg2 + coherence_avg3 + coherence_avg4) / 4\n",
    "\n",
    "# Titles and font size settings\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "font_title = 27\n",
    "font_label = 25\n",
    "font_ticks = 23\n",
    "\n",
    "# Set font to Arial\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "xticks_values = [10, 20, 30, 40, 50] \n",
    "# Plot each graph individually\n",
    "for j in range(3):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5), dpi=400)\n",
    "    ax.semilogy(f, average_coherence[:, j], linewidth=1.5)\n",
    "    ax.set_title(titles[j], fontsize=font_title, fontweight='bold')\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=font_label, fontweight='bold')\n",
    "    ax.set_ylabel('Coherence', fontsize=font_label, fontweight='bold')\n",
    "    ax.set_xlim([1, 50])\n",
    "    ax.set_ylim([10**(-3), 10**(0)])\n",
    "    ax.set_xticks(xticks_values)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=font_ticks, width=2, length=5)  \n",
    "    #ax.tick_params(axis='both', which='minor', width=1, length=4)  \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Remove the top and right spines if not needed\n",
    "  \n",
    "\n",
    "    # Display or save the individual graph\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'coherence_{titles[j].replace(\" \", \"_\")}.png', format='png', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
