{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LFP effects for stimulation on the different channels\n",
    "# Select 2-3 stimulation and recording channels\n",
    "# Plot LFPs, PSDs, STFT, and cross-channel coherence\n",
    "# Pre-stim only\n",
    "\n",
    "#Import Libraries\n",
    "# | echo: false\n",
    "# | warning: false\n",
    "%run C:/Users/27707/Documents/jhu_master/lab/importrhsutilities.py\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spikeinterface as si  # import core only\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.extractors as sse\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.curation as scur\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "from probeinterface import Probe, ProbeGroup\n",
    "from probeinterface import generate_linear_probe, generate_multi_shank\n",
    "from probeinterface import combine_probes\n",
    "from probeinterface.plotting import plot_probe\n",
    "\n",
    "import datetime\n",
    "from uuid import uuid4\n",
    "\n",
    "import numpy as np\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "from pynwb import NWBHDF5IO, NWBFile\n",
    "from pynwb.ecephys import LFP, ElectricalSeries\n",
    "from pprint import pprint\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_names = ['BO3_O5W_Sti_Day1_5uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_10uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_20uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_30uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_40uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_50uA_m.nwb',\n",
    "                   'BO3_O5W_Sti_Day1_60uA_m.nwb'\n",
    "                   ]\n",
    "\n",
    "amps = ['5ua','10ua','20ua',\n",
    "        '30ua','40ua','50ua','60ua']\n",
    "intan_path = 'C:/Users/27707/Documents/jhu_master/LFP_analysis/2024-07-26_DG_3elec/Experimental Set_Final Round_Batch 27/5 Week Old Organoid/Stimulation Day1/'\n",
    "intan_folders = ['5uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_5uA_233uS_240625_161619/merged/',\n",
    "                 '10uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_10uA_233uS_240625_162505/merged/',\n",
    "                 '20uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_20uA_233uS_240625_163352/merged/',\n",
    "                 '30uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_30uA_233uS_240625_164235/merged/',\n",
    "                 '40uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_40uA_233uS_240625_165135/merged/',\n",
    "                 '50uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_50uA_233uS_240625_170022/merged/',\n",
    "                 '60uA_233.3uS_Biphasic Pulse/BO3_O5W_Stimulation_Day1_60uA_233uS_240625_170906/merged/'\n",
    "                 ]\n",
    "\n",
    "recording_names1 = ['BO11_O7W_Sti_Day4_5uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_10uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_20uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_30uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_40uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_50uA_m.nwb',\n",
    "                   'BO11_O7W_Sti_Day4_60uA_m.nwb'\n",
    "                   ]\n",
    "\n",
    "amps1 = ['5ua','10ua','20ua',\n",
    "        '30ua','40ua','50ua','60ua']\n",
    "intan_path1 = 'C:/Users/27707/Documents/jhu_master/LFP_analysis/2024-07-26_DG_3elec/Experimental Set_Final Round_Batch 27/7 Week Old Organoid/Stimulation Day1/'\n",
    "intan_folders1 = ['5uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_5uA_240708_144920/merged/',\n",
    "                 '10uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_10uA_240708_145755/merged/',\n",
    "                 '20uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_20uA_240708_150743/merged/',\n",
    "                 '30uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_30uA_240708_151657/merged/',\n",
    "                 '40uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_40uA_240708_152646/merged/',\n",
    "                 '50uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_50uA_240708_153556/merged/',\n",
    "                 '60uA_233.3uS_Biphasic Pulse/BO11_O7W_Stimulation_Day4_60uA_240708_154509/merged/'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_intan_data(channel_names, signal_data_name,results):\n",
    "    dfs = []\n",
    "    i = 0\n",
    "    for res in results:\n",
    "        #save times for later processing\n",
    "        dict_data = {}\n",
    "        dict_data['time'] = res['t']\n",
    "\n",
    "        #add data for each channel to master df\n",
    "        j = 0\n",
    "        for chan in channel_names:\n",
    "            channel_found, signal_type, signal_index = find_channel_in_header(chan, res)\n",
    "            dict_data[chan] = res[signal_data_name][signal_index,:]/1000 # data is in mV but NWB electrical series type expects V\n",
    "            j += 1\n",
    "        df = pd.DataFrame.from_dict(dict_data)\n",
    "        dfs.append(df)\n",
    "        i+=1\n",
    "    rec_data = pd.concat([dfs[i] for i in range(len(dfs))], axis=0)\n",
    "    rec_data = rec_data.set_index('time')\n",
    "    return rec_data\n",
    "\n",
    "def pull_files(recording_name,fpath='/media/t7/surpass/electrophysiology/Gracias Data/ExperimentalSet_Round2/'):\n",
    "    '''\n",
    "    input:\n",
    "    day - int - day number\n",
    "    recording_name - string - string name of recording folder\n",
    "    '''\n",
    "    filepath = fpath + recording_name + '/*.rhs'\n",
    "    print(filepath)\n",
    "    fnames = glob.glob(filepath)\n",
    "    print(fnames)\n",
    "    results = 0\n",
    "    for i in np.arange(len(fnames)):\n",
    "        res, data_present = load_file(fnames[i])\n",
    "        if i == 0:\n",
    "            results = [res]\n",
    "        else:\n",
    "            results.append(res)\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times_array = []\n",
    "for i in range(len(recording_names)):\n",
    "    BO7_res = pull_files(intan_folders[i], intan_path)\n",
    "    stim_names_BO7 = ['STIM_A-000','STIM_A-002','STIM_A-004']\n",
    "    stim_BO7 = all_intan_data(stim_names_BO7,'stim_data',BO7_res)\n",
    "    stim_times = stim_BO7.loc[(stim_BO7['STIM_A-000'] != 0) | (stim_BO7['STIM_A-002'] != 0) | (stim_BO7['STIM_A-004'] != 0)].index\n",
    "    stim_times_array.append(stim_times.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_start_array = []\n",
    "stim_end_array = []\n",
    "for stim in stim_times_array:\n",
    "    stim = np.insert(stim,0,0)\n",
    "    stim_times_diff = np.diff(stim)\n",
    "    stim_start = stim[np.where(stim_times_diff > 1)[0]+1]\n",
    "    stim_end = stim[np.where(stim_times_diff > 1)[0][1:]]\n",
    "    stim_end = np.concatenate((stim_end,[stim[-1]]))\n",
    "    print(stim_start)\n",
    "    print(stim_end)\n",
    "    stim_start_array.append(stim_start)\n",
    "    stim_end_array.append(stim_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_start_array[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_probe():\n",
    "    north = generate_linear_probe(num_elec=1)\n",
    "    north.rotate(180)\n",
    "    north.set_contacts(positions=[[0,75]])\n",
    "\n",
    "\n",
    "    east = generate_linear_probe(num_elec=1)\n",
    "    east.rotate(90)\n",
    "    east.set_contacts(positions=[[75,0]])\n",
    "\n",
    "    west = generate_linear_probe(num_elec=1)\n",
    "    west.rotate(-90)\n",
    "    west.set_contacts(positions=[[-75,0]])\n",
    "\n",
    "    multi_shank = combine_probes([west, east, north])\n",
    "    plot_probe(multi_shank)\n",
    "    plt.show()\n",
    "    multi_shank.set_device_channel_indices([0,1,2])\n",
    "    return multi_shank\n",
    "\n",
    "def filterbank(recording):\n",
    "    recording_delta = spre.bandpass_filter(recording, freq_min=1, freq_max=4) #delta- moutri paper\n",
    "    recording_100_200 = spre.bandpass_filter(recording, freq_min=100, freq_max=200) #'gamma'- moutri paper\n",
    "    recording_200_400 = spre.bandpass_filter(recording, freq_min=200, freq_max=400) #'gamma'- moutri paper\n",
    "    recording_gamma = spre.bandpass_filter(recording, freq_min=70, freq_max=110) #'ecog high gamma\n",
    "    return recording_delta, recording_100_200, recording_200_400, recording_gamma\n",
    "\n",
    "def downsample_lfp_mua(recording):\n",
    "    recording_lfp = spre.bandpass_filter(recording, freq_min=1, freq_max=400)\n",
    "    recording_lfp = spre.resample(recording_lfp, 1000)\n",
    "    recording_mua = spre.resample(spre.rectify(recording), 1000)\n",
    "    return recording_lfp, recording_mua\n",
    "\n",
    "def load_data(rec_name):\n",
    "    recording = se.read_nwb_recording(rec_name)\n",
    "    multi_shank = gen_probe()\n",
    "    recording = recording.set_probe(multi_shank)\n",
    "    return recording "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = []\n",
    "num_channels = []\n",
    "multirecording = []\n",
    "multirecording_f = []\n",
    "for i in range(len(recording_names)):\n",
    "    recording_names = [folder + 'BO3_O5W_Sti_Day1_' + amp.split('u')[0] + 'uA_m.nwb' \n",
    "                       for folder, amp in zip(intan_folders, amps)]\n",
    "    rec_names = intan_path + recording_names[i]\n",
    "    day_recording = load_data(rec_names)\n",
    "    [num_pre_samples, num_pre_channels] = day_recording.get_traces().shape # Num samples, num channels\n",
    "    num_samples.append(num_pre_samples)\n",
    "    num_channels.append(num_pre_channels)\n",
    "    print('Presample:' + str(num_pre_samples))\n",
    "\n",
    "    # Case 2: the sorter DOES NOT handle multi-segment objects\n",
    "    multirecording_1 = day_recording # The `concatenate_recordings()` mimics a mono-segment object that concatenates all segments\n",
    "    multirecording.append(day_recording) # load your recording using SpikeInterface\n",
    "    multi_shank = gen_probe()\n",
    "    multirecording_filter = spre.bandpass_filter(multirecording[i], freq_min=300, freq_max=6000)\n",
    "    multirecording_f.append(multirecording_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the thresholds for each recording and each channel\n",
    "# # thresholds = [\n",
    "# #     [0.0015, 0.003, 0.0045],  # Thresholds for recording 1\n",
    "# #     [0.002, 0.002, 0.0055],  # Thresholds for recording 2\n",
    "# #     [0.0055, 0.0025, 0.005],  # Thresholds for recording 3\n",
    "# #     [0.006, 0.006, 0.003],  # Thresholds for recording 4\n",
    "# #     [0.006, 0.006, 0.003],  # Thresholds for recording 5\n",
    "# #     [0.006, 0.006, 0.003],  # Thresholds for recording 6\n",
    "# #     [0.006, 0.006, 0.003]   # Thresholds for recording 7\n",
    "# # ]\n",
    "# thresholds = [\n",
    "#     [0.0003, 0.0004, 0.0004],  # Thresholds for recording 1\n",
    "#     [0.0003, 0.0004, 0.0004],  # Thresholds for recording 2\n",
    "#     [0.0005, 0.0004, 0.0003],  # Thresholds for recording 3\n",
    "#     [0.0005, 0.0005, 0.0003],  # Thresholds for recording 4\n",
    "#     [0.0005, 0.0005, 0.0003],  # Thresholds for recording 5\n",
    "#     [0.0005, 0.0005, 0.0003],  # Thresholds for recording 6\n",
    "#     [0.0005, 0.0005, 0.0003],  # Thresholds for recording 7\n",
    "# ]\n",
    "\n",
    "# ms_before = [100]\n",
    "# ms_after = [100]\n",
    "# # Define the range for plotting\n",
    "# # start_index = int(11.6751 * 1e6)\n",
    "# # end_index = int(11.7747 * 1e6)\n",
    "# start_index = int(9.897 * 1e6)\n",
    "# end_index = int(10 * 1e6)\n",
    "# artifact_frames = []\n",
    "# for i in range(len(recording_names)):\n",
    "#     artifact_frames_per_recording = []  # Store artifact frames for each channel in a recording\n",
    "    \n",
    "#     for ch in range(3):  # Assuming there are 3 channels\n",
    "#         channel = multirecording[i].get_traces()[:, ch]\n",
    "        \n",
    "#         # Plot the data in the specified range\n",
    "#         plt.figure()\n",
    "#         plt.plot(channel[start_index:end_index])  # Plotting the data between 2.5x10^6 and 3x10^6\n",
    "        \n",
    "#         # Use predefined threshold for the current recording and channel\n",
    "#         threshold = thresholds[i][ch]\n",
    "#         print(f\"Threshold for recording {i+1}, channel {ch+1}: {threshold}\")\n",
    "        \n",
    "#         # Apply the custom threshold to the entire channel data\n",
    "#         stimulation_trigger_frames = np.where(np.abs(channel) > threshold)\n",
    "        \n",
    "#         # Remove artifacts using the detected triggers\n",
    "#         multirecording_art = spre.remove_artifacts(\n",
    "#             multirecording[i],\n",
    "#             list_triggers=stimulation_trigger_frames[0].tolist(),\n",
    "#             ms_before=ms_before[0],  \n",
    "#             ms_after=ms_after[0]\n",
    "#         )\n",
    "        \n",
    "#         # Plot the artifact-removed data in the specified range\n",
    "#         plt.plot(multirecording_art.get_traces()[:, ch][start_index:end_index])  # Ensure the recording is preprocessed appropriately\n",
    "#         plt.show()\n",
    "    \n",
    "#     artifact_frames.append(artifact_frames_per_recording)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_before = [100]\n",
    "ms_after = [100]\n",
    "#Define the thresholds for each recording and each channel\n",
    "thresholds = [\n",
    "    [0.00025, 0.0004, 0.0004],  # Thresholds for recording 1\n",
    "    [0.0002, 0.00035, 0.0004],  # Thresholds for recording 2\n",
    "    [0.00045, 0.00035, 0.0003],  # Thresholds for recording 3\n",
    "    [0.00045, 0.0005, 0.00025],  # Thresholds for recording 4\n",
    "    [0.00045, 0.0005, 0.00025],  # Thresholds for recording 5\n",
    "    [0.00045, 0.0005, 0.00027],  # Thresholds for recording 6\n",
    "    [0.00045, 0.0005, 0.0003]  # Thresholds for recording 7\n",
    "]\n",
    "\n",
    "\n",
    "artifact_frames = []\n",
    "for i in range(len(recording_names)):\n",
    "    artifact_frames_per_recording = []  # Store artifact frames for each channel in a recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        channel = multirecording[i].get_traces()[:, ch].astype(np.float32)\n",
    "        #plt.figure()\n",
    "        #plt.plot(channel)\n",
    "        \n",
    "        # Use predefined threshold for the current recording and channel\n",
    "        threshold = thresholds[i][ch]\n",
    "        print(f\"Threshold for recording {i+1}, channel {ch+1}: {threshold}\")\n",
    "        \n",
    "        # Apply the custom threshold\n",
    "        stimulation_trigger_frames = np.where(np.abs(channel) > threshold)\n",
    "        \n",
    "        # Remove artifacts using the detected triggers\n",
    "        multirecording_art = spre.remove_artifacts(\n",
    "            multirecording[i],\n",
    "            list_triggers=stimulation_trigger_frames[0].tolist(),\n",
    "            ms_before=ms_before[0],  \n",
    "            ms_after=ms_after[0]\n",
    "        )\n",
    "        \n",
    "        artifact_frames_per_recording.append(stimulation_trigger_frames[0].tolist())\n",
    "        #plt.plot(multirecording_art.get_traces()[:, ch])  # Ensure the recording is preprocessed appropriately\n",
    "        #plt.show()\n",
    "    \n",
    "    artifact_frames.append(artifact_frames_per_recording)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spikeinterface.extractors import NumpyRecording\n",
    "\n",
    "\n",
    "# # Lazy preprocessing\n",
    "# recording_art = []\n",
    "# recording_lfp = []\n",
    "# recording_mua = []\n",
    "# recording_delta = []\n",
    "# recording_100_200 = []\n",
    "# recording_200_400 = []\n",
    "# recording_gamma = []\n",
    "# artifact_frames_resample = []\n",
    "\n",
    "# # Define the notch filter parameters\n",
    "# fs = 1000  # Resampled data to 1000 Hz\n",
    "# f0_60 =60\n",
    "# f0_180 = 180.0  # Power line noise at 60 Hz\n",
    "# Q = 50  # Quality factor for the notch filter\n",
    "# Q1=300\n",
    "# Q2 = 1000\n",
    "# f_300 =300\n",
    "# #Create a notch filter for 60 Hz\n",
    "# b_60, a_60 = signal.iirnotch(f0_60, 20, 30000)\n",
    "# b_200, a_200 = signal.iirnotch(f0_180, Q, 30000)\n",
    "# b_300, a_300 = signal.iirnotch(f_300, Q1, 30000)\n",
    "# for i in range(len(recording_names)):\n",
    "#     rc=[]\n",
    "#     for ch in range(3):\n",
    "    \n",
    "#         recording_artifact_removed = spre.remove_artifacts(\n",
    "#            multirecording[i],\n",
    "#            list_triggers=artifact_frames[i][ch],  # Combine triggers from all channels\n",
    "#            ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust this based on your needs  \n",
    "#         )\n",
    "#         channel_data_artifact_removed = recording_artifact_removed.get_traces()[:, ch]\n",
    "\n",
    "#         rc.append(channel_data_artifact_removed)\n",
    "    \n",
    "#     # Combine the channels into one array\n",
    "#     combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "#     # Create a new RecordingExtractor object with combined data\n",
    "#     sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "#     combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "    \n",
    "#     # Append the filtered recording to the list\n",
    "#     recording_art.append(combined_recording)\n",
    "#     # Apply the 60Hz, 200Hz, and 300Hz notch filters to remove noise\n",
    "#     traces_filtered = signal.filtfilt(b_60, a_60, recording_art[i].get_traces(), axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_60, a_60, traces_filtered, axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_60, a_60, traces_filtered, axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_200, a_200, traces_filtered, axis=0)\n",
    "#     traces_filtered = signal.filtfilt(b_300, a_300, traces_filtered, axis=0)\n",
    "\n",
    "#     # Use NumpyRecording to create a new RecordingExtractor with the filtered traces\n",
    "#     sampling_frequency = recording_artifact_removed.get_sampling_frequency()\n",
    "#     channel_ids = recording_artifact_removed.get_channel_ids()\n",
    "#     recording_filtered = se.NumpyRecording([traces_filtered], sampling_frequency, channel_ids=channel_ids)\n",
    "\n",
    "#     # Process LFP and MUA after filtering\n",
    "#     lfp, mua = downsample_lfp_mua(recording_filtered)\n",
    "\n",
    "#     # total_samples = lfp.get_num_samples()\n",
    "\n",
    "#     # # Apply the 60Hz notch filter multiple times to effectively remove the noise\n",
    "#     # traces_filtered = lfp.get_traces().astype(np.float32)\n",
    "\n",
    "#     # traces_filtered = signal.filtfilt(b_60, a_60, traces_filtered, axis=0)\n",
    "\n",
    "#     # # Use NumpyRecording to create a new RecordingExtractor with the filtered traces\n",
    "#     # sampling_frequency = lfp.get_sampling_frequency()\n",
    "#     # channel_ids = lfp.get_channel_ids()\n",
    "#     # lfp = se.NumpyRecording([traces_filtered], sampling_frequency, channel_ids=channel_ids)\n",
    "\n",
    "#     delta, s100_200, s200_400, gamma = filterbank(lfp)\n",
    "#     recording_lfp.append(lfp)\n",
    "#     recording_mua.append(mua)\n",
    "#     recording_delta.append(delta)\n",
    "#     recording_100_200.append(s100_200)\n",
    "#     recording_200_400.append(s200_400)\n",
    "#     recording_gamma.append(gamma)\n",
    "    \n",
    "#     # Resample artifact frames for further analysis\n",
    "#     stim_frames = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames[i])))\n",
    "#     artifact_frames_resample.append(stim_frames)\n",
    "\n",
    "# time_pre_samples = num_pre_samples / 30000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import numpy as np\n",
    "\n",
    "recording_art = []\n",
    "recording_lfp = []\n",
    "recording_mua = []\n",
    "recording_delta = []\n",
    "recording_100_200 = []\n",
    "recording_200_400 = []\n",
    "recording_gamma = []\n",
    "artifact_frames_resample = []\n",
    "\n",
    "# Create notch filters for specific frequencies\n",
    "#frequencies = [1.4, 9.0, 18.2, 25.0, 27.2, 29.2, 36.4, 37.6, 41.4, 43.8, 45.4, 46.4, 60.0, 180.0, 300.0]\n",
    "frequencies = [60.0, 180.0, 300.0]\n",
    "Q_values = [60.0, 180.0, 300.0]  # Define Q values corresponding to each frequency\n",
    "\n",
    "notch_filters = [signal.iirnotch(f, Q, 30000) for f, Q in zip(frequencies, Q_values)]\n",
    "\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    rc = []\n",
    "    for ch in range(3):\n",
    "        # Remove artifacts for each channel\n",
    "        recording_artifact_removed = spre.remove_artifacts(\n",
    "            multirecording[i],\n",
    "            list_triggers=artifact_frames[i][ch],  # Combine triggers from all channels\n",
    "            ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "        )\n",
    "        channel_data_artifact_removed = recording_artifact_removed.get_traces()[:, ch]\n",
    "\n",
    "        # Append the artifact-removed channel data to rc list\n",
    "        rc.append(channel_data_artifact_removed)\n",
    "\n",
    "    # Combine the channels into one array\n",
    "    combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "    # Create a new RecordingExtractor object with combined data\n",
    "    sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "    combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "\n",
    "    # Append the filtered recording to the list\n",
    "    recording_art.append(combined_recording)\n",
    "\n",
    "    # Apply notch filters sequentially to remove noise at specified frequencies\n",
    "    traces_filtered = recording_art[i].get_traces()\n",
    "    for b, a in notch_filters:\n",
    "        traces_filtered = signal.filtfilt(b, a, traces_filtered, axis=0)\n",
    "\n",
    "    # Create a new RecordingExtractor with the filtered traces\n",
    "    recording_filtered = NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "    # Process LFP and MUA after filtering\n",
    "    lfp, mua = downsample_lfp_mua(recording_filtered)\n",
    "\n",
    "    # Apply filter bank to LFP\n",
    "    delta, s100_200, s200_400, gamma = filterbank(lfp)\n",
    "    recording_lfp.append(lfp)\n",
    "    recording_mua.append(mua)\n",
    "    recording_delta.append(delta)\n",
    "    recording_100_200.append(s100_200)\n",
    "    recording_200_400.append(s200_400)\n",
    "    recording_gamma.append(gamma)\n",
    "\n",
    "    # Resample artifact frames for further analysis\n",
    "    stim_frames = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames[i])))\n",
    "    artifact_frames_resample.append(stim_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as sp_signal  # Rename scipy.signal to avoid conflicts\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import hilbert \n",
    "\n",
    "# Helper functions\n",
    "def extract_phase(signal):\n",
    "    \"\"\"Extract the instantaneous phase of a signal using Hilbert transform\"\"\"\n",
    "    analytic_signal = hilbert(signal)\n",
    "    phase = np.angle(analytic_signal)\n",
    "    return phase\n",
    "\n",
    "def calculate_plv(phases):\n",
    "    \"\"\"Compute Phase Locking Value (PLV) between multiple signals\"\"\"\n",
    "    n_signals = phases.shape[0]\n",
    "    plv_matrix = np.zeros((n_signals, n_signals))\n",
    "    for i in range(n_signals):\n",
    "        for j in range(i + 1, n_signals):\n",
    "            phase_diff = phases[i] - phases[j]\n",
    "            plv_matrix[i, j] = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "            plv_matrix[j, i] = plv_matrix[i, j]\n",
    "    return plv_matrix\n",
    "\n",
    "def bandpass_filter(signal, lowcut, highcut, fs, order=4):\n",
    "    \"\"\"Apply a bandpass filter\"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = sp_signal.butter(order, [low, high], btype=\"band\")\n",
    "    filtered_signal = sp_signal.filtfilt(b, a, signal, axis=0)\n",
    "    return filtered_signal\n",
    "\n",
    "def calculate_band_plv(traces_filtered, fs, lowcut, highcut):\n",
    "    \"\"\"Compute PLV for a specific frequency band\"\"\"\n",
    "    band_filtered = np.array([bandpass_filter(traces_filtered[:, ch], lowcut, highcut, fs) for ch in range(traces_filtered.shape[1])])\n",
    "    phases = np.array([extract_phase(band_filtered[ch]) for ch in range(band_filtered.shape[0])])\n",
    "    plv_matrix = calculate_plv(phases)\n",
    "    return plv_matrix\n",
    "\n",
    "\n",
    "# Iterate over recordings\n",
    "for i in range(len(recording_art)):\n",
    "    # Extract LFP signal\n",
    "    lfp = recording_lfp[i].get_traces()\n",
    "    fs = recording_lfp[i].get_sampling_frequency()\n",
    "    start_time = stim_start_array[i][1] + 0.7  # Start time (seconds)\n",
    "    end_time = start_time + 1.5  # End time (seconds)\n",
    "\n",
    "    start_sample = int(start_time * fs)\n",
    "    end_sample = int(end_time * fs)\n",
    "    lfp = lfp[start_sample:end_sample, :] \n",
    "    fs = recording_lfp[i].get_sampling_frequency()\n",
    "\n",
    "    # Compute original PLV for the 1-10 Hz band\n",
    "    plv_5_20hz_original = calculate_band_plv(lfp, fs, 1, 10)\n",
    "    print(f\"Recording {i}: Original PLV for 5-20 Hz:\\n{plv_5_20hz_original}\")\n",
    "\n",
    "    lfp_notch_filtered = lfp.copy()\n",
    "\n",
    "    # Compute PLV after Notch filtering for 11-20 Hz\n",
    "    plv_5_20hz_filtered = calculate_band_plv(lfp_notch_filtered, fs, 11, 20.0)\n",
    "    print(f\"Recording {i}: PLV for 5-20 Hz after Notch Filtering:\\n{plv_5_20hz_filtered}\")\n",
    "\n",
    "    # Function to visualize the PLV matrix\n",
    "    def visualize_plv(plv_matrix, title):\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(plv_matrix, annot=True, cmap=\"viridis\", xticklabels=[\"Ch1\", \"Ch2\", \"Ch3\"], yticklabels=[\"Ch1\", \"Ch2\", \"Ch3\"])\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Channels\")\n",
    "        plt.ylabel(\"Channels\")\n",
    "        plt.show()\n",
    "\n",
    "    # Visualize PLV matrices for original and filtered signals\n",
    "    visualize_plv(plv_5_20hz_original, f\"Original PLV for 5-20 Hz (Recording {i})\")\n",
    "    visualize_plv(plv_5_20hz_filtered, f\"PLV for 5-20 Hz after Notch Filtering (Recording {i})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as sp_signal  # Rename scipy.signal to avoid conflicts\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import hilbert \n",
    "\n",
    "# Helper functions\n",
    "def extract_phase(signal):\n",
    "    \"\"\"Extract the instantaneous phase of a signal using the Hilbert transform\"\"\"\n",
    "    analytic_signal = hilbert(signal)\n",
    "    phase = np.angle(analytic_signal)\n",
    "    return phase\n",
    "\n",
    "def calculate_pli(phases):\n",
    "    \"\"\"Compute Phase Lag Index (PLI) between multiple signals\"\"\"\n",
    "    n_signals = phases.shape[0]\n",
    "    pli_matrix = np.zeros((n_signals, n_signals))\n",
    "    for i in range(n_signals):\n",
    "        for j in range(i + 1, n_signals):\n",
    "            phase_diff = phases[i] - phases[j]\n",
    "            pli_matrix[i, j] = np.abs(np.mean(np.sign(np.sin(phase_diff))))\n",
    "            pli_matrix[j, i] = pli_matrix[i, j]\n",
    "    return pli_matrix\n",
    "\n",
    "def bandpass_filter(signal, lowcut, highcut, fs, order=4):\n",
    "    \"\"\"Apply a bandpass filter\"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = sp_signal.butter(order, [low, high], btype=\"band\")\n",
    "    filtered_signal = sp_signal.filtfilt(b, a, signal, axis=0)\n",
    "    return filtered_signal\n",
    "\n",
    "def calculate_band_pli(traces_filtered, fs, lowcut, highcut):\n",
    "    \"\"\"Compute PLI for a specific frequency band\"\"\"\n",
    "    band_filtered = np.array([bandpass_filter(traces_filtered[:, ch], lowcut, highcut, fs) for ch in range(traces_filtered.shape[1])])\n",
    "    phases = np.array([extract_phase(band_filtered[ch]) for ch in range(band_filtered.shape[0])])\n",
    "    pli_matrix = calculate_pli(phases)\n",
    "    return pli_matrix\n",
    "\n",
    "# Iterate over recordings\n",
    "for i in range(len(recording_art)):\n",
    "    # Extract LFP signal\n",
    "    lfp = recording_lfp[i].get_traces()\n",
    "    fs = recording_lfp[i].get_sampling_frequency()\n",
    "    start_time = stim_start_array[i][1] + 0.7  # Start time (seconds)\n",
    "    end_time = start_time + 1.5  # End time (seconds)\n",
    "\n",
    "    start_sample = int(start_time * fs)\n",
    "    end_sample = int(end_time * fs)\n",
    "    lfp = lfp[start_sample:end_sample, :] \n",
    "\n",
    "    # Step 1: Compute PLI for the 1-10 Hz original signal\n",
    "    pli_1_10hz_original = calculate_band_pli(lfp, fs, 55, 65)\n",
    "    print(f\"Recording {i}: Original PLI for 1-10 Hz:\\n{pli_1_10hz_original}\")\n",
    "\n",
    "    # Step 2: Compute PLI for the 11-20 Hz filtered signal\n",
    "    pli_11_20hz_filtered = calculate_band_pli(lfp, fs, 50, 60)\n",
    "    print(f\"Recording {i}: PLI for 11-20 Hz:\\n{pli_11_20hz_filtered}\")\n",
    "\n",
    "    # Function to visualize the PLI matrix\n",
    "    def visualize_pli(pli_matrix, title):\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(pli_matrix, annot=True, cmap=\"coolwarm\", xticklabels=[\"Ch1\", \"Ch2\", \"Ch3\"], yticklabels=[\"Ch1\", \"Ch2\", \"Ch3\"])\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Channels\")\n",
    "        plt.ylabel(\"Channels\")\n",
    "        plt.show()\n",
    "\n",
    "    # Visualize PLI matrices for the original and filtered signals\n",
    "    visualize_pli(pli_1_10hz_original, f\"Original PLI for 1-10 Hz (Recording {i})\")\n",
    "    visualize_pli(pli_11_20hz_filtered, f\"PLI for 11-20 Hz (Recording {i})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "# Extract LFP data from the preprocessed recording_lfp\n",
    "lfp_data = recording_lfp[1].get_traces()  # Assuming recording_lfp[0] is a RecordingExtractor\n",
    "\n",
    "# Check the shape of lfp_data to confirm its dimensions\n",
    "print(f\"LFP data shape: {lfp_data.shape}\")  # Output the shape to confirm it is 2D (num_samples, num_channels)\n",
    "\n",
    "# If the LFP data contains multiple channels, select one channel for analysis, e.g., the first channel\n",
    "lfp_channel_data = lfp_data[:, 0]  # Select the first channel\n",
    "\n",
    "# Step 1: Compute the power spectral density (PSD) for the 1-20 Hz band\n",
    "f, Pxx = signal.welch(lfp_channel_data, fs=1000, nperseg=400)\n",
    "\n",
    "# Step 2: Plot the power spectral density to identify noise in the 1-20 Hz band\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(f, Pxx)\n",
    "plt.xlim([1, 400])  # Limit the frequency range to 1-20 Hz\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Power Spectral Density [V^2/Hz]')\n",
    "plt.title('Power Spectral Density (1-20 Hz)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Use STFT to analyze frequency components in the 1-20 Hz range\n",
    "f_stft, t_stft, Zxx = signal.stft(lfp_channel_data, fs=1000, nperseg=400)\n",
    "\n",
    "# Plot the STFT results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pcolormesh(t_stft, f_stft, np.abs(Zxx), shading='gouraud')\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.ylim([1, 50])  # Limit the frequency range to 1-20 Hz\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.title('STFT Magnitude (1-20 Hz)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import signal\n",
    "\n",
    "# # Extract LFP data from the preprocessed recording_lfp\n",
    "# lfp_data = recording_lfp[0].get_traces()  # Assuming recording_lfp[0] is a RecordingExtractor object\n",
    "\n",
    "# # Check the shape of lfp_data to confirm its dimensions\n",
    "# print(f\"LFP data shape: {lfp_data.shape}\")  # Output the shape to confirm it is 2D (num_samples, num_channels)\n",
    "\n",
    "# # If the LFP data contains multiple channels, select one channel for analysis, e.g., the first channel\n",
    "# lfp_channel_data = lfp_data[:, 0]  # Select the first channel\n",
    "\n",
    "# fs = 1000  # Assume the sampling rate is 1000 Hz\n",
    "\n",
    "# # Define notch filter frequencies\n",
    "# f0_60 = 60  # 60 Hz noise frequency\n",
    "# f0_200 = 180  # First noise frequency at 200 Hz\n",
    "# f0_300 = 300.0  # Second noise frequency at 300 Hz\n",
    "# Q = 100  # Quality factor of the notch filter, controlling bandwidth\n",
    "\n",
    "# # Create notch filters for 60 Hz, 200 Hz, and 300 Hz\n",
    "# b_60, a_60 = signal.iirnotch(f0_60, Q, fs)\n",
    "# b_200, a_200 = signal.iirnotch(f0_200, Q, fs)\n",
    "# b_300, a_300 = signal.iirnotch(f0_300, Q, fs)\n",
    "\n",
    "# # Apply notch filters to remove noise at 60 Hz, 200 Hz, and 300 Hz\n",
    "# filtered_lfp_data = signal.filtfilt(b_60, a_60, lfp_channel_data)\n",
    "# filtered_lfp_data = signal.filtfilt(b_200, a_200, filtered_lfp_data)\n",
    "# filtered_lfp_data = signal.filtfilt(b_300, a_300, filtered_lfp_data)\n",
    "\n",
    "# # Step 1: Compute the power spectral density (PSD) of the filtered signal\n",
    "# f_filtered, Pxx_filtered = signal.welch(filtered_lfp_data, fs=fs, nperseg=400)\n",
    "\n",
    "# # Step 2: Plot the power spectral density after filtering\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.semilogy(f_filtered, Pxx_filtered)\n",
    "# plt.xlim([1, 400])  # Limit the frequency range to 5-400 Hz\n",
    "# plt.xlabel('Frequency [Hz]')\n",
    "# plt.ylabel('Power Spectral Density [V^2/Hz]')\n",
    "# plt.title('Filtered Power Spectral Density (5-400 Hz)')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Step 3: Use STFT to analyze frequency components in the 5-400 Hz range\n",
    "# f_stft, t_stft, Zxx = signal.stft(filtered_lfp_data, fs=fs, nperseg=400)\n",
    "\n",
    "# # Plot the STFT results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.pcolormesh(t_stft, f_stft, np.abs(Zxx), shading='gouraud')\n",
    "# plt.colorbar(label='Magnitude')\n",
    "# plt.ylim([1, 400])  # Limit the frequency range to 5-400 Hz\n",
    "# plt.xlabel('Time [sec]')\n",
    "# plt.ylabel('Frequency [Hz]')\n",
    "# plt.title('Filtered STFT Magnitude (5-400 Hz)')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 +25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data = multirecording[0].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[1000000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[0].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[500000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 + 29  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[0].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[6000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5* 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[0].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 +25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data = multirecording[1].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[1000000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 + 25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[1].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[1000000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[1].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5* 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[1].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20uA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data = multirecording[2].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[1200000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[2].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], :])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[2].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5* 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[2].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60  + 25# 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data = multirecording[3].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[1000000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 +25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[3].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[1000000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[3].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5* 60 + 59  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[3].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[7000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 +25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data = multirecording[4].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[1000000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 +25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[4].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[1000000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5* 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[4].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 +25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data = multirecording[5].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[1000000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 +25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[5].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[1000000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5* 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[5].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 +25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data = multirecording[6].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[1500000], time_axis[2300000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 30000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 +25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_art[6].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[1500000], time_axis[2500000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 + 25  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[6].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 5 * 60 + 25 # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[6].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "#    axs[i].set_xlim([time_axis[0], time_axis[35109]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "nperseg = 0.25*fs_stim  # Window size for coherence calculation\n",
    "time_buffer = 0.6\n",
    " #seconds before/after stimulus, to avoid artifacts\n",
    "overlap = int(0.5 * nperseg)  # 25% overlap of the window size\n",
    "time_period =  1.5 #seconds\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[0][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[0].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg1 = coherence_sum / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f, coherence_avg1[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[1][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[1].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg2 = coherence_sum / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f, coherence_avg2[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[2][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[2].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg3 = coherence_sum / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f, coherence_avg3[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[3][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[3].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg4 = coherence_sum / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f, coherence_avg4[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[4][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[4].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg5 = coherence_sum / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f, coherence_avg5[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[5][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[5].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg6 = coherence_sum / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f, coherence_avg6[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[6][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[6].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f, Cxy_post = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum[:, j] += Cxy_post  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f, Cxy_post)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg7 = coherence_sum / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f, coherence_avg7[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array to store the average coherence values for all recordings\n",
    "all_coherence_avg = np.zeros((int(nperseg / 2 + 1), 7, 3))  # 7 recordings, 3 coherence pairs\n",
    "\n",
    "# Assign the precomputed coherence averages to the all_coherence_avg array\n",
    "all_coherence_avg[:, 0, :] = coherence_avg1\n",
    "all_coherence_avg[:, 1, :] = coherence_avg2\n",
    "all_coherence_avg[:, 2, :] = coherence_avg3\n",
    "all_coherence_avg[:, 3, :] = coherence_avg4\n",
    "all_coherence_avg[:, 4, :] = coherence_avg5\n",
    "all_coherence_avg[:, 5, :] = coherence_avg6\n",
    "all_coherence_avg[:, 6, :] = coherence_avg7\n",
    "\n",
    "# Plot average coherence curves in separate figures for each pair\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "labels = [f'{i}' for i in amps]\n",
    "\n",
    "for j in range(3):  # Loop over each of the three coherence pairs\n",
    "    fig, ax = plt.subplots(dpi=400, figsize=(5, 5))\n",
    "\n",
    "    for k in range(7):\n",
    "        ax.semilogy(f, all_coherence_avg[:, k, j], label=labels[k], color=colors[k])\n",
    "\n",
    "    ax.set_title(f'Average Coherence - {titles[j]}')\n",
    "    ax.set_xlabel('Frequency [Hz]')\n",
    "    ax.set_ylabel('Coherence')\n",
    "    ax.set_xlim([1, 50])\n",
    "    ax.set_ylim([10**(-3), 10**(0)])\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times_array1 = []\n",
    "for i in range(len(recording_names1)):\n",
    "    BO7_res1 = pull_files(intan_folders1[i], intan_path1)\n",
    "    stim_names_BO71 = ['STIM_A-000','STIM_A-002','STIM_A-004']\n",
    "    stim_BO71 = all_intan_data(stim_names_BO71,'stim_data',BO7_res1)\n",
    "    stim_times1 = stim_BO71.loc[(stim_BO71['STIM_A-000'] != 0) | (stim_BO71['STIM_A-002'] != 0) | (stim_BO71['STIM_A-004'] != 0)].index\n",
    "    stim_times_array1.append(stim_times1.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_start_array1 = []\n",
    "stim_end_array1 = []\n",
    "for stim in stim_times_array1:\n",
    "    stim = np.insert(stim,0,0)\n",
    "    stim_times_diff1 = np.diff(stim)\n",
    "    stim_start1 = stim[np.where(stim_times_diff1 > 1)[0]+1]\n",
    "    stim_end1 = stim[np.where(stim_times_diff1 > 1)[0][1:]]\n",
    "    stim_end1 = np.concatenate((stim_end1,[stim[-1]]))\n",
    "    print(stim_start1)\n",
    "    print(stim_end1)\n",
    "    stim_start_array1.append(stim_start1)\n",
    "    stim_end_array1.append(stim_end1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples1 = []\n",
    "num_channels1 = []\n",
    "multirecording1 = []\n",
    "multirecording_f1 = []\n",
    "for i in range(len(recording_names1)):\n",
    "    recording_names1 = [folder + 'BO11_O7W_Sti_Day4_' + amp.split('u')[0] + 'uA_m.nwb' \n",
    "                       for folder, amp in zip(intan_folders1, amps1)]\n",
    "    rec_names1 = intan_path1 + recording_names1[i]\n",
    "    day_recording1 = load_data(rec_names1)\n",
    "    [num_pre_samples1, num_pre_channels1] = day_recording1.get_traces().shape # Num samples, num channels\n",
    "    num_samples1.append(num_pre_samples1)\n",
    "    num_channels1.append(num_pre_channels1)\n",
    "    print('Presample:' + str(num_pre_samples1))\n",
    "\n",
    "    # Case 2: the sorter DOES NOT handle multi-segment objects\n",
    "    multirecording_1 = day_recording1 # The `concatenate_recordings()` mimics a mono-segment object that concatenates all segments\n",
    "    multirecording1.append(day_recording1) # load your recording using SpikeInterface\n",
    "    multi_shank1 = gen_probe()\n",
    "    multirecording_filter1 = spre.bandpass_filter(multirecording1[i], freq_min=300, freq_max=6000)\n",
    "    multirecording_f1.append(multirecording_filter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_before = [100]\n",
    "ms_after = [100]\n",
    "\n",
    "#Define the thresholds for each recording and each channel\n",
    "thresholds1 = [\n",
    "    [0.00005, 0.0002, 0.00035],  # Thresholds for recording 1\n",
    "    [0.00025, 0.0004, 0.00037],  # Thresholds for recording 2\n",
    "    [0.0003, 0.0004, 0.0005],  # Thresholds for recording 3\n",
    "    [0.0003, 0.0005, 0.0005],  # Thresholds for recording 4\n",
    "    [0.0003, 0.0005, 0.0005],  # Thresholds for recording 5\n",
    "    [0.0004, 0.0005, 0.0005],  # Thresholds for recording 6\n",
    "    [0.0004, 0.0005, 0.0005]  # Thresholds for recording 7\n",
    "]\n",
    "\n",
    "artifact_frames1 = []\n",
    "for i in range(len(recording_names1)):\n",
    "    artifact_frames_per_recording1 = []  # Store artifact frames for each channel in a recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        channel1 = multirecording1[i].get_traces()[:, ch].astype(np.float32)\n",
    "        #plt.figure()\n",
    "        #plt.plot(channel)\n",
    "        \n",
    "        # Use predefined threshold for the current recording and channel\n",
    "        threshold1 = thresholds1[i][ch]\n",
    "        print(f\"Threshold for recording {i+1}, channel {ch+1}: {threshold1}\")\n",
    "        \n",
    "        # Apply the custom threshold\n",
    "        stimulation_trigger_frames1 = np.where(np.abs(channel1) > threshold1)\n",
    "        \n",
    "        # Remove artifacts using the detected triggers\n",
    "        multirecording_art1 = spre.remove_artifacts(\n",
    "            multirecording1[i],\n",
    "            list_triggers=stimulation_trigger_frames1[0].tolist(),\n",
    "            ms_before=ms_before[0],  \n",
    "            ms_after=ms_after[0]\n",
    "        )\n",
    "        \n",
    "        artifact_frames_per_recording1.append(stimulation_trigger_frames1[0].tolist())\n",
    "        #plt.plot(multirecording_art.get_traces()[:, ch])  # Ensure the recording is preprocessed appropriately\n",
    "        #plt.show()\n",
    "    \n",
    "    artifact_frames1.append(artifact_frames_per_recording1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import numpy as np\n",
    "\n",
    "recording_art1 = []\n",
    "recording_lfp1 = []\n",
    "recording_mua1= []\n",
    "recording_delta1 = []\n",
    "recording_100_2001 = []\n",
    "recording_200_4001 = []\n",
    "recording_gamma1 = []\n",
    "artifact_frames_resample1 = []\n",
    "\n",
    "# Create notch filters for specific frequencies\n",
    "#frequencies = [1.4, 9.0, 18.2, 25.0, 27.2, 29.2, 36.4, 37.6, 41.4, 43.8, 45.4, 46.4, 60.0, 180.0, 300.0]\n",
    "frequencies = [60.0, 180.0, 300.0]\n",
    "Q_values = [60.0, 180.0, 300.0]  # Define Q values corresponding to each frequency\n",
    "\n",
    "notch_filters = [signal.iirnotch(f, Q, 30000) for f, Q in zip(frequencies, Q_values)]\n",
    "\n",
    "\n",
    "for i in range(len(recording_names1)):\n",
    "    rc1 = []\n",
    "    for ch in range(3):\n",
    "        # Remove artifacts for each channel\n",
    "        recording_artifact_removed1 = spre.remove_artifacts(\n",
    "            multirecording1[i],\n",
    "            list_triggers=artifact_frames1[i][ch],  # Combine triggers from all channels\n",
    "            ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "        )\n",
    "        channel_data_artifact_removed1 = recording_artifact_removed1.get_traces()[:, ch]\n",
    "\n",
    "        # Append the artifact-removed channel data to rc list\n",
    "        rc1.append(channel_data_artifact_removed1)\n",
    "\n",
    "    # Combine the channels into one array\n",
    "    combined_data1 = np.stack(rc1, axis=1)  # Stack along the channel axis\n",
    "\n",
    "    # Create a new RecordingExtractor object with combined data\n",
    "    sampling_frequency = multirecording1[i].get_sampling_frequency()\n",
    "    combined_recording1 = NumpyRecording(traces_list=[combined_data1], sampling_frequency=sampling_frequency)\n",
    "\n",
    "    # Append the filtered recording to the list\n",
    "    recording_art1.append(combined_recording1)\n",
    "\n",
    "    # Apply notch filters sequentially to remove noise at specified frequencies\n",
    "    traces_filtered = recording_art1[i].get_traces()\n",
    "    for b, a in notch_filters:\n",
    "        traces_filtered = signal.filtfilt(b, a, traces_filtered, axis=0)\n",
    "\n",
    "    # Create a new RecordingExtractor with the filtered traces\n",
    "    recording_filtered1 = NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "    # Process LFP and MUA after filtering\n",
    "    lfp1, mua1 = downsample_lfp_mua(recording_filtered1)\n",
    "\n",
    "    # Apply filter bank to LFP\n",
    "    delta1, s100_2001, s200_4001, gamma1 = filterbank(lfp)\n",
    "    recording_lfp1.append(lfp1)\n",
    "    recording_mua1.append(mua1)\n",
    "    recording_delta1.append(delta1)\n",
    "    recording_100_2001.append(s100_2001)\n",
    "    recording_200_4001.append(s200_4001)\n",
    "    recording_gamma1.append(gamma1)\n",
    "\n",
    "    # Resample artifact frames for further analysis\n",
    "    stim_frames1 = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames1[i])))\n",
    "    artifact_frames_resample1.append(stim_frames1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spikeinterface.extractors import NumpyRecording\n",
    "# import numpy as np\n",
    "# import pywt\n",
    "\n",
    "# # Define a wavelet denoising function\n",
    "# def wavelet_denoise(data, wavelet='db4', level=4):\n",
    "#     # Perform wavelet decomposition\n",
    "#     coeffs = pywt.wavedec(data, wavelet, mode='per', level=level)\n",
    "#     # Set denoising threshold\n",
    "#     sigma = (1/0.6745) * np.median(np.abs(coeffs[-1] - np.median(coeffs[-1])))\n",
    "#     uthresh = sigma * np.sqrt(2 * np.log(len(data)))\n",
    "#     # Apply soft thresholding\n",
    "#     coeffs[1:] = [pywt.threshold(i, value=uthresh, mode='soft') for i in coeffs[1:]]\n",
    "#     # Reconstruct the signal\n",
    "#     reconstructed_signal = pywt.waverec(coeffs, wavelet, mode='per')\n",
    "#     return reconstructed_signal\n",
    "\n",
    "# # Data preprocessing and analysis\n",
    "# recording_art1 = []\n",
    "# recording_lfp1 = []\n",
    "# recording_mua1 = []\n",
    "# recording_delta1 = []\n",
    "# recording_100_2001 = []\n",
    "# recording_200_4001 = []\n",
    "# recording_gamma1 = []\n",
    "# artifact_frames_resample1 = []\n",
    "\n",
    "# for i in range(len(recording_names1)):\n",
    "#     rc1 = []\n",
    "#     for ch in range(3):\n",
    "#         # Remove artifacts from the recording\n",
    "#         recording_artifact_removed1 = spre.remove_artifacts(\n",
    "#             multirecording1[i],\n",
    "#             list_triggers=artifact_frames1[i][ch],\n",
    "#             ms_before=ms_before[0], ms_after=ms_after[0]\n",
    "#         )\n",
    "#         channel_data_artifact_removed1 = recording_artifact_removed1.get_traces()[:, ch]\n",
    "\n",
    "#         # Apply wavelet denoising\n",
    "#         channel_data_artifact_removed1 = wavelet_denoise(channel_data_artifact_removed1)\n",
    "\n",
    "#         # Add single-channel data to the rc list\n",
    "#         rc1.append(channel_data_artifact_removed1)\n",
    "\n",
    "#     # Combine the channels into one array\n",
    "#     combined_data1 = np.stack(rc1, axis=1)\n",
    "\n",
    "#     # Create a new RecordingExtractor object\n",
    "#     combined_recording1 = NumpyRecording(traces_list=[combined_data1], sampling_frequency=multirecording1[i].get_sampling_frequency())\n",
    "#     recording_art1.append(combined_recording1)\n",
    "\n",
    "#     # Process LFP and MUA after wavelet denoising\n",
    "#     lfp1, mua1 = downsample_lfp_mua(combined_recording1)\n",
    "\n",
    "#     # Apply filter bank processing to extract frequency bands\n",
    "#     delta1, s100_2001, s200_4001, gamma1 = filterbank(lfp1)\n",
    "#     recording_lfp1.append(lfp1)\n",
    "#     recording_mua1.append(mua1)\n",
    "#     recording_delta1.append(delta1)\n",
    "#     recording_100_2001.append(s100_2001)\n",
    "#     recording_200_4001.append(s200_4001)\n",
    "#     recording_gamma1.append(gamma1)\n",
    "\n",
    "#     # Resample artifact frames for further analysis\n",
    "#     stim_frames1 = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames1[i])))\n",
    "#     artifact_frames_resample1.append(stim_frames1)\n",
    "\n",
    "# # Output: Data processing complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "# Extract LFP data from the preprocessed recording_lfp\n",
    "lfp_data1 = recording_lfp1[0].get_traces()  # Assuming recording_lfp[0] is a RecordingExtractor\n",
    "\n",
    "# Check the shape of lfp_data to confirm its dimensions\n",
    "print(f\"LFP data shape: {lfp_data1.shape}\")  # Output the shape to confirm it is 2D (num_samples, num_channels)\n",
    "\n",
    "# If the LFP data contains multiple channels, select one channel for analysis, e.g., the first channel\n",
    "lfp_channel_data1 = lfp_data1[:, 0]  # Select the first channel\n",
    "\n",
    "# Step 1: Compute the power spectral density (PSD) for the 1-20 Hz band\n",
    "f_20, Pxx = signal.welch(lfp_channel_data1, fs=1000, nperseg=400)\n",
    "\n",
    "# Step 2: Plot the power spectral density to detect noise in the 1-20 Hz band\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(f_20, Pxx)\n",
    "plt.xlim([1, 400])  # Limit the frequency range to 1-20 Hz\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Power Spectral Density [V^2/Hz]')\n",
    "plt.title('Power Spectral Density (1-20 Hz)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Use STFT to analyze frequency components in the 1-20 Hz range\n",
    "f_stft, t_stft, Zxx = signal.stft(lfp_channel_data1, fs=1000, nperseg=400)\n",
    "\n",
    "# Plot the STFT results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pcolormesh(t_stft, f_stft, np.abs(Zxx), shading='gouraud')\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.ylim([1, 400])  # Limit the frequency range to 1-20 Hz\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.title('STFT Magnitude (1-20 Hz)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5uA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "nperseg1 = 0.25*fs_stim  # Window size for coherence calculation\n",
    "time_buffer1 = 0.6 #seconds before/after stimulus, to avoid artifacts\n",
    "time_period = 1.5 #seconds\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum1 = np.zeros((int(nperseg1/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array1[0][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment1 = recording_lfp1[0].get_traces()[int(pulse_time * fs_stim + time_buffer1 * fs_stim):int((pulse_time + time_buffer1 + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post1 = segment1[:, ind1[j]]\n",
    "        y_post1 = segment1[:, ind2[j]]\n",
    "        f1, Cxy_post1 = signal.coherence(x_post1, y_post1, fs_stim, nperseg=nperseg1, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum1[:, j] += Cxy_post1  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f1, Cxy_post1)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg11 = coherence_sum1 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f1, coherence_avg11[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum1 = np.zeros((int(nperseg1/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array1[1][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment1 = recording_lfp1[1].get_traces()[int(pulse_time * fs_stim + time_buffer1 * fs_stim):int((pulse_time + time_buffer1 + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post1 = segment1[:, ind1[j]]\n",
    "        y_post1 = segment1[:, ind2[j]]\n",
    "        f1, Cxy_post1 = signal.coherence(x_post1, y_post1, fs_stim, nperseg=nperseg1, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum1[:, j] += Cxy_post1  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f1, Cxy_post1)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg12 = coherence_sum1 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f1, coherence_avg12[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum1 = np.zeros((int(nperseg1/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array1[2][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment1 = recording_lfp1[2].get_traces()[int(pulse_time * fs_stim + time_buffer1 * fs_stim):int((pulse_time + time_buffer1 + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post1 = segment1[:, ind1[j]]\n",
    "        y_post1 = segment1[:, ind2[j]]\n",
    "        f1, Cxy_post1 = signal.coherence(x_post1, y_post1, fs_stim, nperseg=nperseg1, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum1[:, j] += Cxy_post1  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f1, Cxy_post1)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg13 = coherence_sum1 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f1, coherence_avg13[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum1 = np.zeros((int(nperseg1/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array1[3][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment1 = recording_lfp1[3].get_traces()[int(pulse_time * fs_stim + time_buffer1 * fs_stim):int((pulse_time + time_buffer1 + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post1 = segment1[:, ind1[j]]\n",
    "        y_post1 = segment1[:, ind2[j]]\n",
    "        f1, Cxy_post1 = signal.coherence(x_post1, y_post1, fs_stim, nperseg=nperseg1, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum1[:, j] += Cxy_post1  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f1, Cxy_post1)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg14 = coherence_sum1 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f1, coherence_avg14[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum1 = np.zeros((int(nperseg1/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array1[4][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment1 = recording_lfp1[4].get_traces()[int(pulse_time * fs_stim + time_buffer1 * fs_stim):int((pulse_time + time_buffer1 + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post1 = segment1[:, ind1[j]]\n",
    "        y_post1 = segment1[:, ind2[j]]\n",
    "        f1, Cxy_post1 = signal.coherence(x_post1, y_post1, fs_stim, nperseg=nperseg1, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum1[:, j] += Cxy_post1  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f1, Cxy_post1)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg15 = coherence_sum1 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f1, coherence_avg15[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum1 = np.zeros((int(nperseg1/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array1[5][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment1 = recording_lfp1[5].get_traces()[int(pulse_time * fs_stim + time_buffer1 * fs_stim):int((pulse_time + time_buffer1 + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post1 = segment1[:, ind1[j]]\n",
    "        y_post1 = segment1[:, ind2[j]]\n",
    "        f1, Cxy_post1 = signal.coherence(x_post1, y_post1, fs_stim, nperseg=nperseg1, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum1[:, j] += Cxy_post1  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f1, Cxy_post1)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg16 = coherence_sum1 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f1, coherence_avg16[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60uA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "\n",
    "coherence_sum1 = np.zeros((int(nperseg1/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array1[6][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment1 = recording_lfp1[6].get_traces()[int(pulse_time * fs_stim + time_buffer1 * fs_stim):int((pulse_time + time_buffer1 + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post1 = segment1[:, ind1[j]]\n",
    "        y_post1 = segment1[:, ind2[j]]\n",
    "        f1, Cxy_post1 = signal.coherence(x_post1, y_post1, fs_stim, nperseg=nperseg1, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum1[:, j] += Cxy_post1  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f1, Cxy_post1)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([1, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg17 = coherence_sum1 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f1, coherence_avg17[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([1, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array to store the average coherence values for all recordings\n",
    "all_coherence_avg1 = np.zeros((int(nperseg1 / 2 + 1), 7, 3))  # 7 recordings, 3 coherence pairs\n",
    "\n",
    "# Assign the precomputed coherence averages to the all_coherence_avg array\n",
    "all_coherence_avg1[:, 0, :] = coherence_avg11\n",
    "all_coherence_avg1[:, 1, :] = coherence_avg12\n",
    "all_coherence_avg1[:, 2, :] = coherence_avg13\n",
    "all_coherence_avg1[:, 3, :] = coherence_avg14\n",
    "all_coherence_avg1[:, 4, :] = coherence_avg15\n",
    "all_coherence_avg1[:, 5, :] = coherence_avg16\n",
    "all_coherence_avg1[:, 6, :] = coherence_avg17\n",
    "\n",
    "# Plot average coherence curves in separate figures for each pair\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "labels = [f'{i}' for i in amps]\n",
    "\n",
    "for j in range(3):  # Loop over each of the three coherence pairs\n",
    "    fig, ax = plt.subplots(dpi=400, figsize=(5, 5))\n",
    "\n",
    "    for k in range(7):\n",
    "        ax.semilogy(f1, all_coherence_avg1[:, k, j], label=labels[k], color=colors[k])\n",
    "\n",
    "    ax.set_title(f'Average Coherence - {titles[j]}')\n",
    "    ax.set_xlabel('Frequency [Hz]')\n",
    "    ax.set_ylabel('Coherence')\n",
    "    ax.set_xlim([1, 50])\n",
    "    ax.set_ylim([10**(-3), 10**(0)])\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_names = ['BO5_O7W_Sti_Day4_5uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_10uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_20uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_30uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_40uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_50uA_m.nwb',\n",
    "                   'BO5_O7W_Sti_Day4_60uA_m.nwb'\n",
    "                   ]\n",
    "\n",
    "amps = ['5ua','10ua','20ua',\n",
    "        '30ua','40ua','50ua','60ua']\n",
    "intan_path = 'C:/Users/27707/Documents/jhu_master/LFP_analysis/2024-07-26_DG_3elec/Experimental Set_Final Round_Batch 27/7 Week Old Organoid/Stimulation Day1/'\n",
    "intan_folders = ['5uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_5uA_240708_122554/merged/',\n",
    "                 '10uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_10uA_240708_123516/merged/',\n",
    "                 '20uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_20uA_240708_124435/merged/',\n",
    "                 '30uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_30uA_240708_125400/merged/',\n",
    "                 '40uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_40uA_240708_130304/merged/',\n",
    "                 '50uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_50uA_240708_131207/merged/',\n",
    "                 '60uA_233.3uS_Biphasic Pulse/BO5_O7W_Stimulation_Day4_60uA_240708_132110/merged/'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times_array = []\n",
    "for i in range(len(recording_names)):\n",
    "    BO7_res = pull_files(intan_folders[i], intan_path)\n",
    "    stim_names_BO7 = ['STIM_A-000','STIM_A-002','STIM_A-004']\n",
    "    stim_BO7 = all_intan_data(stim_names_BO7,'stim_data',BO7_res)\n",
    "    stim_times = stim_BO7.loc[(stim_BO7['STIM_A-000'] != 0) | (stim_BO7['STIM_A-002'] != 0) | (stim_BO7['STIM_A-004'] != 0)].index\n",
    "    stim_times_array.append(stim_times.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_start_array = []\n",
    "stim_end_array = []\n",
    "for stim in stim_times_array:\n",
    "    stim = np.insert(stim,0,0)\n",
    "    stim_times_diff = np.diff(stim)\n",
    "    stim_start = stim[np.where(stim_times_diff > 1)[0]+1]\n",
    "    stim_end = stim[np.where(stim_times_diff > 1)[0][1:]]\n",
    "    stim_end = np.concatenate((stim_end,[stim[-1]]))\n",
    "    print(stim_start)\n",
    "    print(stim_end)\n",
    "    stim_start_array.append(stim_start)\n",
    "    stim_end_array.append(stim_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = []\n",
    "num_channels = []\n",
    "multirecording = []\n",
    "multirecording_f = []\n",
    "for i in range(len(recording_names)):\n",
    "    recording_names = [folder + 'BO5_O7W_Sti_Day4_' + amp.split('u')[0] + 'uA_240708_m.nwb' \n",
    "                       for folder, amp in zip(intan_folders, amps)]\n",
    "    rec_names = intan_path + recording_names[i]\n",
    "    day_recording = load_data(rec_names)\n",
    "    [num_pre_samples, num_pre_channels] = day_recording.get_traces().shape # Num samples, num channels\n",
    "    num_samples.append(num_pre_samples)\n",
    "    num_channels.append(num_pre_channels)\n",
    "    print('Presample:' + str(num_pre_samples))\n",
    "\n",
    "    # Case 2: the sorter DOES NOT handle multi-segment objects\n",
    "    multirecording_1 = day_recording # The `concatenate_recordings()` mimics a mono-segment object that concatenates all segments\n",
    "    multirecording.append(day_recording) # load your recording using SpikeInterface\n",
    "    multi_shank = gen_probe()\n",
    "    multirecording_filter = spre.bandpass_filter(multirecording[i], freq_min=300, freq_max=6000)\n",
    "    multirecording_f.append(multirecording_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_before = [100]\n",
    "ms_after = [100]\n",
    "# Define the thresholds for each recording and each channel\n",
    "\n",
    "thresholds = [\n",
    "    [0.00005, 0.0002, 0.00035],  # Thresholds for recording 1\n",
    "    [0.00025, 0.0004, 0.00037],  # Thresholds for recording 2\n",
    "    [0.00025, 0.00045, 0.0005],  # Thresholds for recording 3\n",
    "    [0.0003, 0.0005, 0.0005],  # Thresholds for recording 4\n",
    "    [0.00035, 0.0005, 0.0005],  # Thresholds for recording 5\n",
    "    [0.0004, 0.0005, 0.0005],  # Thresholds for recording 6\n",
    "    [0.0004, 0.0005, 0.0005]  # Thresholds for recording 7\n",
    "]\n",
    "\n",
    "artifact_frames = []\n",
    "for i in range(len(recording_names)):\n",
    "    artifact_frames_per_recording = []  # Store artifact frames for each channel in a recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        channel = multirecording[i].get_traces()[:, ch].astype(np.float32)\n",
    "        # plt.figure()\n",
    "        # plt.plot(channel)\n",
    "        \n",
    "        # Use predefined threshold for the current recording and channel\n",
    "        threshold = thresholds[i][ch]\n",
    "        print(f\"Threshold for recording {i+1}, channel {ch+1}: {threshold}\")\n",
    "        \n",
    "        # Apply the custom threshold\n",
    "        stimulation_trigger_frames = np.where(np.abs(channel) > threshold)\n",
    "        \n",
    "        # Remove artifacts using the detected triggers\n",
    "        multirecording_art = spre.remove_artifacts(\n",
    "            multirecording[i],\n",
    "            list_triggers=stimulation_trigger_frames[0].tolist(),\n",
    "            ms_before=ms_before[0],  \n",
    "            ms_after=ms_after[0]\n",
    "        )\n",
    "        \n",
    "        artifact_frames_per_recording.append(stimulation_trigger_frames[0].tolist())\n",
    "        # plt.plot(multirecording_art.get_traces()[:, ch])  # Ensure the recording is preprocessed appropriately\n",
    "        # plt.show()\n",
    "    \n",
    "    artifact_frames.append(artifact_frames_per_recording)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import numpy as np\n",
    "\n",
    "recording_art = []\n",
    "recording_lfp = []\n",
    "recording_mua = []\n",
    "recording_delta = []\n",
    "recording_100_200 = []\n",
    "recording_200_400 = []\n",
    "recording_gamma = []\n",
    "artifact_frames_resample = []\n",
    "\n",
    "# Create notch filters for specific frequencies\n",
    "#frequencies = [1.4, 9.0, 18.2, 25.0, 27.2, 29.2, 36.4, 37.6, 41.4, 43.8, 45.4, 46.4, 60.0, 180.0, 300.0]\n",
    "frequencies = [60.0, 180.0, 300.0]\n",
    "Q_values = [60.0, 180.0, 300.0]  # Define Q values corresponding to each frequency\n",
    "\n",
    "notch_filters = [signal.iirnotch(f, Q, 30000) for f, Q in zip(frequencies, Q_values)]\n",
    "\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    rc = []\n",
    "    for ch in range(3):\n",
    "        # Remove artifacts for each channel\n",
    "        recording_artifact_removed = spre.remove_artifacts(\n",
    "            multirecording[i],\n",
    "            list_triggers=artifact_frames[i][ch],  # Combine triggers from all channels\n",
    "            ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "        )\n",
    "        channel_data_artifact_removed = recording_artifact_removed.get_traces()[:, ch]\n",
    "\n",
    "        # Append the artifact-removed channel data to rc list\n",
    "        rc.append(channel_data_artifact_removed)\n",
    "\n",
    "    # Combine the channels into one array\n",
    "    combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "    # Create a new RecordingExtractor object with combined data\n",
    "    sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "    combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "\n",
    "    # Append the filtered recording to the list\n",
    "    recording_art.append(combined_recording)\n",
    "\n",
    "    # Apply notch filters sequentially to remove noise at specified frequencies\n",
    "    traces_filtered = recording_art[i].get_traces()\n",
    "    for b, a in notch_filters:\n",
    "        traces_filtered = signal.filtfilt(b, a, traces_filtered, axis=0)\n",
    "\n",
    "    # Create a new RecordingExtractor with the filtered traces\n",
    "    recording_filtered = NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "    # Process LFP and MUA after filtering\n",
    "    lfp, mua = downsample_lfp_mua(recording_filtered)\n",
    "\n",
    "    # Apply filter bank to LFP\n",
    "    delta, s100_200, s200_400, gamma = filterbank(lfp)\n",
    "    recording_lfp.append(lfp)\n",
    "    recording_mua.append(mua)\n",
    "    recording_delta.append(delta)\n",
    "    recording_100_200.append(s100_200)\n",
    "    recording_200_400.append(s200_400)\n",
    "    recording_gamma.append(gamma)\n",
    "\n",
    "    # Resample artifact frames for further analysis\n",
    "    stim_frames = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames[i])))\n",
    "    artifact_frames_resample.append(stim_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum2 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[0][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[0].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f2, Cxy_post2 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum2[:, j] += Cxy_post2  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f2, Cxy_post2)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg21 = coherence_sum2 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f2, coherence_avg21[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum2 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[1][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[1].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f2, Cxy_post2 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum2[:, j] += Cxy_post2  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f2, Cxy_post2)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg22 = coherence_sum2 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f2, coherence_avg22[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum2 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[2][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[2].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f2, Cxy_post2 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum2[:, j] += Cxy_post2  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f2, Cxy_post2)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg23 = coherence_sum2 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f2, coherence_avg23[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum2 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[3][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[3].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f2, Cxy_post2 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum2[:, j] += Cxy_post2  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f2, Cxy_post2)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg24 = coherence_sum2 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f2, coherence_avg24[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum2 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[4][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[4].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f2, Cxy_post2 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum2[:, j] += Cxy_post2  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f2, Cxy_post2)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg25 = coherence_sum2 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f2, coherence_avg25[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum2 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[5][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[5].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f2, Cxy_post2 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum2[:, j] += Cxy_post2  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f2, Cxy_post2)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg26 = coherence_sum2 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f2, coherence_avg26[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum2 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[6][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[6].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f2, Cxy_post2 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum2[:, j] += Cxy_post2  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f2, Cxy_post2)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg27 = coherence_sum2 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f2, coherence_avg27[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array to store the average coherence values for all recordings\n",
    "all_coherence_avg2 = np.zeros((int(nperseg / 2 + 1), 7, 3))  # 7 recordings, 3 coherence pairs\n",
    "\n",
    "# Assign the precomputed coherence averages to the all_coherence_avg array\n",
    "all_coherence_avg2[:, 0, :] = coherence_avg21\n",
    "all_coherence_avg2[:, 1, :] = coherence_avg22\n",
    "all_coherence_avg2[:, 2, :] = coherence_avg23\n",
    "all_coherence_avg2[:, 3, :] = coherence_avg24\n",
    "all_coherence_avg2[:, 4, :] = coherence_avg25\n",
    "all_coherence_avg2[:, 5, :] = coherence_avg26\n",
    "all_coherence_avg2[:, 6, :] = coherence_avg27\n",
    "\n",
    "# Plot average coherence curves in separate figures for each pair\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "labels = [f'{i}' for i in amps]\n",
    "\n",
    "for j in range(3):  # Loop over each of the three coherence pairs\n",
    "    fig, ax = plt.subplots(dpi=400, figsize=(10, 8))\n",
    "\n",
    "    for k in range(7):\n",
    "        ax.semilogy(f2, all_coherence_avg2[:, k, j], label=labels[k], color=colors[k])\n",
    "\n",
    "    ax.set_title(f'Average Coherence - {titles[j]}')\n",
    "    ax.set_xlabel('Frequency [Hz]')\n",
    "    ax.set_ylabel('Coherence')\n",
    "    ax.set_xlim([1, 400])\n",
    "    ax.set_ylim([10**(-3), 10**(0)])\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_names = ['BO11_O5W_Sti_Day1_5uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_10uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_20uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_30uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_40uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_50uA_m.nwb',\n",
    "                   'BO11_O5W_Sti_Day1_60uA_m.nwb'\n",
    "                   ]\n",
    "\n",
    "amps = ['5ua','10ua','20ua',\n",
    "        '30ua','40ua','50ua','60ua']\n",
    "intan_path = 'C:/Users/27707/Documents/jhu_master/LFP_analysis/2024-07-26_DG_3elec/Experimental Set_Final Round_Batch 27/5 Week Old Organoid/Stimulation Day1/'\n",
    "intan_folders = ['5uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_5uA_233uS_240625_123952/merged/',\n",
    "                 '10uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_10uA_233uS_240625_125131/merged/',\n",
    "                 '20uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_20uA_233uS_240625_130048/merged/',\n",
    "                 '30uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_30uA_233uS_240625_130939/merged/',\n",
    "                 '40uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_40uA_233uS_240625_131833/merged/',\n",
    "                 '50uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_50uA_233uS_240625_132735/merged/',\n",
    "                 '60uA_233.3uS_Biphasic Pulse/BO11_O5W_Stimulation_Day1_60uA_233uS_240625_133646/merged/'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times_array = []\n",
    "for i in range(len(recording_names)):\n",
    "    BO7_res = pull_files(intan_folders[i], intan_path)\n",
    "    stim_names_BO7 = ['STIM_A-000','STIM_A-002','STIM_A-004']\n",
    "    stim_BO7 = all_intan_data(stim_names_BO7,'stim_data',BO7_res)\n",
    "    stim_times = stim_BO7.loc[(stim_BO7['STIM_A-000'] != 0) | (stim_BO7['STIM_A-002'] != 0) | (stim_BO7['STIM_A-004'] != 0)].index\n",
    "    stim_times_array.append(stim_times.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_start_array = []\n",
    "stim_end_array = []\n",
    "for stim in stim_times_array:\n",
    "    stim = np.insert(stim,0,0)\n",
    "    stim_times_diff = np.diff(stim)\n",
    "    stim_start = stim[np.where(stim_times_diff > 1)[0]+1]\n",
    "    stim_end = stim[np.where(stim_times_diff > 1)[0][1:]]\n",
    "    stim_end = np.concatenate((stim_end,[stim[-1]]))\n",
    "    print(stim_start)\n",
    "    print(stim_end)\n",
    "    stim_start_array.append(stim_start)\n",
    "    stim_end_array.append(stim_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = []\n",
    "num_channels = []\n",
    "multirecording = []\n",
    "multirecording_f = []\n",
    "for i in range(len(recording_names)):\n",
    "    recording_names = [folder + 'BO11_O5W_Sti_Day1_' + amp.split('u')[0] + 'uA_m.nwb'\n",
    "                       for folder, amp in zip(intan_folders, amps)]\n",
    "    rec_names = intan_path + recording_names[i]\n",
    "    day_recording = load_data(rec_names)\n",
    "    [num_pre_samples, num_pre_channels] = day_recording.get_traces().shape # Num samples, num channels\n",
    "    num_samples.append(num_pre_samples)\n",
    "    num_channels.append(num_pre_channels)\n",
    "    print('Presample:' + str(num_pre_samples))\n",
    "\n",
    "    # Case 2: the sorter DOES NOT handle multi-segment objects\n",
    "    multirecording_1 = day_recording # The `concatenate_recordings()` mimics a mono-segment object that concatenates all segments\n",
    "    multirecording.append(day_recording) # load your recording using SpikeInterface\n",
    "    multi_shank = gen_probe()\n",
    "    multirecording_filter = spre.bandpass_filter(multirecording[i], freq_min=300, freq_max=6000)\n",
    "    multirecording_f.append(multirecording_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Calculate RMS-based thresholds for each recording and channel\n",
    "fs = 30000  # Replace with your actual sampling rate\n",
    "start_time = 0 # Start at 10 seconds\n",
    "end_time = 455  # End at 210 seconds\n",
    "num_samples = fs * (end_time - start_time)  # Calculate the number of samples for 200 seconds\n",
    "\n",
    "thresholds = []  # Initialize an empty list to store thresholds for each recording\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    thresholds_per_recording = []  # Store thresholds for each channel in the current recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        # Extract the channel data from the 10th second to the 210th second of signal\n",
    "        channel = multirecording[i].get_traces()[start_time * fs:end_time * fs, ch].astype(np.float32)\n",
    "\n",
    "        # Calculate the RMS value and determine the threshold\n",
    "        rms_value = np.sqrt(np.mean(channel**2))\n",
    "        threshold = rms_value * 5\n",
    "        thresholds_per_recording.append(threshold)\n",
    "    \n",
    "    thresholds.append(thresholds_per_recording)\n",
    "\n",
    "# Now, use the thresholds in the original artifact detection code\n",
    "ms_before = [100]\n",
    "ms_after = [100]\n",
    "artifact_frames = []\n",
    "\n",
    "# Original loop for artifact detection\n",
    "for i in range(len(recording_names)):\n",
    "    artifact_frames_per_recording = []  # Store artifact frames for each channel in a recording\n",
    "    \n",
    "    for ch in range(3):  # Assuming there are 3 channels\n",
    "        channel = multirecording[i].get_traces()[:, ch].astype(np.float32)\n",
    "        \n",
    "        # Use predefined threshold for the current recording and channel\n",
    "        threshold = thresholds[i][ch]\n",
    "        print(f\"Threshold for recording {i+1}, channel {ch+1}: {threshold}\")\n",
    "        \n",
    "        # Apply the custom threshold\n",
    "        stimulation_trigger_frames = np.where(np.abs(channel) > threshold)\n",
    "\n",
    "        # Remove artifacts using the detected triggers\n",
    "        if stimulation_trigger_frames[0].size > 0:  # Check if there are any detected triggers\n",
    "            multirecording_art = spre.remove_artifacts(\n",
    "                multirecording[i],\n",
    "                list_triggers=stimulation_trigger_frames[0].tolist(),\n",
    "                ms_before=ms_before[0],  \n",
    "                ms_after=ms_after[0]\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No artifacts detected for recording {i+1}, channel {ch+1}\")\n",
    "        \n",
    "        artifact_frames_per_recording.append(stimulation_trigger_frames[0].tolist())\n",
    "\n",
    "    artifact_frames.append(artifact_frames_per_recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from spikeinterface.extractors import NumpyRecording\n",
    "import numpy as np\n",
    "\n",
    "recording_art = []\n",
    "recording_lfp = []\n",
    "recording_mua = []\n",
    "recording_delta = []\n",
    "recording_100_200 = []\n",
    "recording_200_400 = []\n",
    "recording_gamma = []\n",
    "artifact_frames_resample = []\n",
    "\n",
    "# Create notch filters for specific frequencies\n",
    "#frequencies = [1.4, 9.0, 18.2, 25.0, 27.2, 29.2, 36.4, 37.6, 41.4, 43.8, 45.4, 46.4, 60.0, 180.0, 300.0]\n",
    "frequencies = [60.0, 180.0, 300.0]\n",
    "Q_values = [60.0, 180.0, 300.0]  # Define Q values corresponding to each frequency\n",
    "\n",
    "notch_filters = [signal.iirnotch(f, Q, 30000) for f, Q in zip(frequencies, Q_values)]\n",
    "\n",
    "\n",
    "for i in range(len(recording_names)):\n",
    "    rc = []\n",
    "    for ch in range(3):\n",
    "        # Remove artifacts for each channel\n",
    "        recording_artifact_removed = spre.remove_artifacts(\n",
    "            multirecording[i],\n",
    "            list_triggers=artifact_frames[i][ch],  # Combine triggers from all channels\n",
    "            ms_before=ms_before[0], ms_after=ms_after[0]  # Adjust based on your needs\n",
    "        )\n",
    "        channel_data_artifact_removed = recording_artifact_removed.get_traces()[:, ch]\n",
    "\n",
    "        # Append the artifact-removed channel data to rc list\n",
    "        rc.append(channel_data_artifact_removed)\n",
    "\n",
    "    # Combine the channels into one array\n",
    "    combined_data = np.stack(rc, axis=1)  # Stack along the channel axis\n",
    "\n",
    "    # Create a new RecordingExtractor object with combined data\n",
    "    sampling_frequency = multirecording[i].get_sampling_frequency()\n",
    "    combined_recording = NumpyRecording(traces_list=[combined_data], sampling_frequency=sampling_frequency)\n",
    "\n",
    "    # Append the filtered recording to the list\n",
    "    recording_art.append(combined_recording)\n",
    "\n",
    "    # Apply notch filters sequentially to remove noise at specified frequencies\n",
    "    traces_filtered = recording_art[i].get_traces()\n",
    "    for b, a in notch_filters:\n",
    "        traces_filtered = signal.filtfilt(b, a, traces_filtered, axis=0)\n",
    "\n",
    "    # Create a new RecordingExtractor with the filtered traces\n",
    "    recording_filtered = NumpyRecording([traces_filtered], sampling_frequency)\n",
    "\n",
    "    # Process LFP and MUA after filtering\n",
    "    lfp, mua = downsample_lfp_mua(recording_filtered)\n",
    "\n",
    "    # Apply filter bank to LFP\n",
    "    delta, s100_200, s200_400, gamma = filterbank(lfp)\n",
    "    recording_lfp.append(lfp)\n",
    "    recording_mua.append(mua)\n",
    "    recording_delta.append(delta)\n",
    "    recording_100_200.append(s100_200)\n",
    "    recording_200_400.append(s200_400)\n",
    "    recording_gamma.append(gamma)\n",
    "\n",
    "    # Resample artifact frames for further analysis\n",
    "    stim_frames = list(map(lambda x: int(x * (1000 / 30000)), np.concatenate(artifact_frames[i])))\n",
    "    artifact_frames_resample.append(stim_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "# Extract LFP data from the preprocessed recording_lfp\n",
    "lfp_data = recording_lfp[3].get_traces()  # Assuming recording_lfp[0] is a RecordingExtractor\n",
    "\n",
    "# Check the shape of lfp_data to confirm its dimensions\n",
    "print(f\"LFP data shape: {lfp_data.shape}\")  # Output the shape to confirm it is 2D (num_samples, num_channels)\n",
    "\n",
    "# If the LFP data contains multiple channels, select one channel for analysis, e.g., the first channel\n",
    "lfp_channel_data = lfp_data[:, 2]  # Select the third channel\n",
    "\n",
    "# Step 1: Compute the power spectral density (PSD) for the 1-20 Hz band\n",
    "f_20, Pxx = signal.welch(lfp_channel_data, fs=1000, nperseg=400)\n",
    "\n",
    "# Step 2: Plot the power spectral density to detect noise in the 1-20 Hz band\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(f_20, Pxx)\n",
    "plt.xlim([1, 400])  # Limit the frequency range to 1-20 Hz\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Power Spectral Density [V^2/Hz]')\n",
    "plt.title('Power Spectral Density (1-20 Hz)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Use STFT to analyze frequency components in the 1-20 Hz range\n",
    "f_stft, t_stft, Zxx = signal.stft(lfp_channel_data, fs=1000, nperseg=400)\n",
    "\n",
    "# Plot the STFT results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pcolormesh(t_stft, f_stft, np.abs(Zxx), shading='gouraud')\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.ylim([1, 400])  # Limit the frequency range to 1-20 Hz\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.title('STFT Magnitude (1-20 Hz)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 0  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[1].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    #axs[i].set_xlim([time_axis[0], time_axis[14400000]])\n",
    "    # axs[i].set_xlim([time_axis[6900000], time_axis[8000000]])\n",
    "    #axs[i].set_ylim([-0.000025, 0.000025])\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameter settings\n",
    "fs = 1000  # Sampling frequency (Hz)\n",
    "delay_after_stim = 0.6  # Delay time after stimulation (s)\n",
    "signal_duration = 1.5  # Duration of the signal to extract (s)\n",
    "\n",
    "# Convert to sample points\n",
    "delay_samples = int(delay_after_stim * fs)\n",
    "duration_samples = int(signal_duration * fs)\n",
    "\n",
    "# Initialize an array to store the average signals\n",
    "num_channels = raw_data_post.shape[1]\n",
    "average_signals = []\n",
    "\n",
    "# Iterate through each channel\n",
    "for channel_idx in range(num_channels):\n",
    "    channel_data = raw_data_post[:, channel_idx]\n",
    "    extracted_signals = []\n",
    "    \n",
    "    # Iterate through each stimulation start time\n",
    "    for stim_start in stim_start_array[1]:  # Assuming stim_start_array corresponds to the first channel\n",
    "        stim_start_sample = int(stim_start * fs)  # Convert to sample points\n",
    "        start_sample = stim_start_sample + delay_samples\n",
    "        end_sample = start_sample + duration_samples\n",
    "        \n",
    "        # Ensure valid indices\n",
    "        if start_sample >= 0 and end_sample <= len(channel_data):\n",
    "            segment = channel_data[start_sample:end_sample]\n",
    "            extracted_signals.append(segment)\n",
    "    \n",
    "    # Compute the average signal\n",
    "    if extracted_signals:\n",
    "        avg_signal = np.mean(extracted_signals, axis=0)\n",
    "        average_signals.append(avg_signal)\n",
    "\n",
    "# Time axis (1.5s interval)\n",
    "time_axis = np.linspace(delay_after_stim, delay_after_stim + signal_duration, duration_samples)\n",
    "\n",
    "# Plot the average signals\n",
    "plt.figure(figsize=(10, 6))\n",
    "for channel_idx, avg_signal in enumerate(average_signals):\n",
    "    plt.plot(time_axis, avg_signal, label=f'Channel {channel_idx + 1}')\n",
    "plt.axvline(delay_after_stim, color='red', linestyle='--', label='Stimulus Start + 0.6s')  # Mark post-stimulation delay time\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude (V)')\n",
    "plt.title('Average Signals (1.5s After 0.6s Delay Post-Stimulation)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Parameter settings\n",
    "fs = 1000  # Sampling frequency (Hz)\n",
    "delay_after_stim = 0.6  # Delay after stimulation (s)\n",
    "signal_duration = 1.5  # Duration of the signal to extract (s)\n",
    "nperseg = 256  # STFT segment length\n",
    "\n",
    "# Convert parameters to sample points\n",
    "delay_samples = int(delay_after_stim * fs)\n",
    "duration_samples = int(signal_duration * fs)\n",
    "\n",
    "# Initialize storage for signal segments\n",
    "time_freq_results = []\n",
    "\n",
    "# Extract signal segments for each channel and perform time-frequency analysis\n",
    "for channel_idx in range(3):  # Assume we are analyzing only the first three channels\n",
    "    channel_data = raw_data_post[:, channel_idx]\n",
    "    channel_segments = []\n",
    "    for stim_start in stim_start_array[0]:  # Assume stim_start_array corresponds to the first stimulus sequence\n",
    "        stim_start_sample = int(stim_start * fs)\n",
    "        start_sample = stim_start_sample + delay_samples\n",
    "        end_sample = start_sample + duration_samples\n",
    "        \n",
    "        # Ensure valid index range\n",
    "        if start_sample >= 0 and end_sample <= len(channel_data):\n",
    "            segment = channel_data[start_sample:end_sample]\n",
    "            # Time-frequency analysis\n",
    "            f, t, Zxx = stft(segment, fs, nperseg=nperseg)\n",
    "            channel_segments.append(np.abs(Zxx))  # Extract magnitude spectrum\n",
    "    time_freq_results.append(channel_segments)\n",
    "\n",
    "# Compute the average time-frequency distribution for each channel\n",
    "avg_time_freq_distributions = [np.mean(np.array(segments), axis=0) for segments in time_freq_results]\n",
    "\n",
    "# Compute cosine similarity\n",
    "reference = avg_time_freq_distributions[0].flatten()  # Use the first channel as the reference\n",
    "cosine_similarities = [\n",
    "    cosine_similarity(reference.reshape(1, -1), dist.flatten().reshape(1, -1))[0, 0]\n",
    "    for dist in avg_time_freq_distributions\n",
    "]\n",
    "\n",
    "# Plot time-frequency distributions\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for channel_idx, avg_dist in enumerate(avg_time_freq_distributions):\n",
    "    axs[channel_idx].pcolormesh(t, f, avg_dist, shading='gouraud')\n",
    "    axs[channel_idx].set_title(f'Channel {channel_idx + 1} - Time-Frequency')\n",
    "    axs[channel_idx].set_xlabel('Time (s)')\n",
    "    axs[channel_idx].set_ylabel('Frequency (Hz)')\n",
    "    axs[channel_idx].set_ylim(1, 50) \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Output cosine similarity values\n",
    "for i, similarity in enumerate(cosine_similarities):\n",
    "    print(f'Cosine similarity of Channel {i+1} to Channel 1: {similarity:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "fs = 1000  # Sampling frequency (30kHz)\n",
    "time_window = 0  # 5 minutes in seconds\n",
    "start_sample = int(time_window * fs)  # Starting sample at the 5-minute mark\n",
    "\n",
    "# Extract the data from 5 minutes to the end\n",
    "raw_data_post = recording_lfp[6].get_traces()[start_sample:, :]\n",
    "\n",
    "# Calculate the time axis for the plot\n",
    "time_axis = np.arange(start_sample, start_sample + raw_data_post.shape[0]) / fs\n",
    "\n",
    "# Plot the raw signal for each channel\n",
    "num_channels = raw_data_post.shape[1]\n",
    "fig, axs = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for i in range(num_channels):\n",
    "    axs[i].plot(time_axis, raw_data_post[:, i])\n",
    "    axs[i].set_title(f'Channel {i+1}')\n",
    "    axs[i].set_ylabel('Amplitude (V)')\n",
    "    axs[i].set_xlim([time_axis[0], time_axis[480000]])\n",
    "\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the average amplitude for each channel\n",
    "average_amplitudes = np.mean(np.abs(raw_data_post), axis=0)\n",
    "for i, avg_amp in enumerate(average_amplitudes):\n",
    "    print(f'Average amplitude for Channel {i+1}: {avg_amp:.6f} V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "fs_stim = 1000  # Sampling frequency for stimulus data\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(5, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum3 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[0][:4]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[0].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f3, Cxy_post3 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum3[:, j] += Cxy_post3  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f3, Cxy_post3)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg31 = coherence_sum3 / 4\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[4, j].semilogy(f3, coherence_avg31[:, j])\n",
    "    axs[4, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[4, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[4, j].set_ylabel('Coherence')\n",
    "    axs[4, j].set_xlim([5, 400])\n",
    "    axs[4, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum3 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[1][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[1].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f3, Cxy_post3 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum3[:, j] += Cxy_post3  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f3, Cxy_post3)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg32 = coherence_sum3 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f3, coherence_avg32[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum3 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[2][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[2].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f3, Cxy_post3 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum3[:, j] += Cxy_post3  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f3, Cxy_post3)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg33 = coherence_sum3 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f3, coherence_avg33[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum3 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[3][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[3].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f3, Cxy_post3 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum3[:, j] += Cxy_post3  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f3, Cxy_post3)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg34 = coherence_sum3 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f3, coherence_avg34[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum3 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[4][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[4].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f3, Cxy_post3 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum3[:, j] += Cxy_post3  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f3, Cxy_post3)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg35 = coherence_sum3 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f3, coherence_avg35[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum3 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[5][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[5].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f3, Cxy_post3 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum3[:, j] += Cxy_post3  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f3, Cxy_post3)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg36 = coherence_sum3 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f3, coherence_avg36[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, sharex=True, sharey=True, dpi=400, figsize=(16, 18))  # Six rows, three columns\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "ind1 = [0, 0, 1]\n",
    "ind2 = [1, 2, 2]\n",
    "\n",
    "coherence_sum3 = np.zeros((int(nperseg/2+1), 3))  # Initialize an array to store sum of coherence values\n",
    "\n",
    "# Step 2: Calculate Post-Stimulus Coherence (100 ms after each of the first five pulses)\n",
    "for i, pulse_time in enumerate(stim_start_array[6][:5]):  # Iterate over the first 5 pulse times\n",
    "    segment = recording_lfp[6].get_traces()[int(pulse_time * fs_stim + time_buffer * fs_stim):int((pulse_time + time_buffer + time_period) * fs_stim), :]\n",
    "    \n",
    "    for j in range(3):\n",
    "        x_post = segment[:, ind1[j]]\n",
    "        y_post = segment[:, ind2[j]]\n",
    "        f3, Cxy_post3 = signal.coherence(x_post, y_post, fs_stim, nperseg=nperseg, noverlap=overlap)\n",
    "        \n",
    "        coherence_sum3[:, j] += Cxy_post3  # Accumulate coherence values\n",
    "        \n",
    "        axs[i, j].semilogy(f3, Cxy_post3)\n",
    "        axs[i, j].set_title(f'{titles[j]} (Pulse {i+1})')\n",
    "        axs[i, j].set_xlabel('Frequency [Hz]')\n",
    "        axs[i, j].set_ylabel('Coherence')\n",
    "        axs[i, j].set_xlim([5, 400])\n",
    "        axs[i, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "# Calculate the average coherence\n",
    "coherence_avg37 = coherence_sum3 / 5\n",
    "\n",
    "# Plot the average coherence in the last row\n",
    "for j in range(3):\n",
    "    axs[5, j].semilogy(f3, coherence_avg37[:, j])\n",
    "    axs[5, j].set_title(f'{titles[j]} (Average)')\n",
    "    axs[5, j].set_xlabel('Frequency [Hz]')\n",
    "    axs[5, j].set_ylabel('Coherence')\n",
    "    axs[5, j].set_xlim([5, 400])\n",
    "    axs[5, j].set_ylim([10**(-3), 10**(0)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array to store the average coherence values for all recordings\n",
    "all_coherence_avg3 = np.zeros((int(nperseg / 2 + 1), 7, 3))  # 7 recordings, 3 coherence pairs\n",
    "\n",
    "# Assign the precomputed coherence averages to the all_coherence_avg array\n",
    "all_coherence_avg3[:, 0, :] = coherence_avg31\n",
    "all_coherence_avg3[:, 1, :] = coherence_avg32\n",
    "all_coherence_avg3[:, 2, :] = coherence_avg33\n",
    "all_coherence_avg3[:, 3, :] = coherence_avg34\n",
    "all_coherence_avg3[:, 4, :] = coherence_avg35\n",
    "all_coherence_avg3[:, 5, :] = coherence_avg36\n",
    "all_coherence_avg3[:, 6, :] = coherence_avg37\n",
    "\n",
    "# Plot average coherence curves in separate figures for each pair\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "labels = [f'{i}' for i in amps]\n",
    "\n",
    "for j in range(3):  # Loop over each of the three coherence pairs\n",
    "    fig, ax = plt.subplots(dpi=400, figsize=(10, 8))\n",
    "\n",
    "    for k in range(7):\n",
    "        ax.semilogy(f3, all_coherence_avg3[:, k, j], label=labels[k], color=colors[k])\n",
    "\n",
    "    ax.set_title(f'Average Coherence - {titles[j]}')\n",
    "    ax.set_xlabel('Frequency [Hz]')\n",
    "    ax.set_ylabel('Coherence')\n",
    "    ax.set_xlim([1, 50])\n",
    "    ax.set_ylim([10**(-3), 10**(0)])\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Initialize arrays for interpolated coherence data\n",
    "interp_coherence1 = np.zeros((f.size, 7, 3))\n",
    "interp_coherence2 = np.zeros((f.size, 7, 3))\n",
    "interp_coherence3 = np.zeros((f.size, 7, 3))\n",
    "interp_coherence4 = np.zeros((f.size, 7, 3))\n",
    "\n",
    "# Perform interpolation for two datasets\n",
    "for i in range(7):  # 7 recordings\n",
    "    for j in range(3):  # Each recording has 3 coherence pairs\n",
    "            interp_func1 = interp1d(f1, all_coherence_avg1[:, i, j], kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "            interp_func2 = interp1d(f, all_coherence_avg[:, i, j], kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "            interp_func3 = interp1d(f2, all_coherence_avg2[:, i, j], kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "            interp_func4 = interp1d(f3, all_coherence_avg3[:, i, j], kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n",
    "            # Apply interpolation to the common frequency range\n",
    "            interp_coherence1[:, i, j] = interp_func1(f)\n",
    "            interp_coherence2[:, i, j] = interp_func2(f)\n",
    "            interp_coherence3[:, i, j] = interp_func3(f)\n",
    "            interp_coherence4[:, i, j] = interp_func4(f)\n",
    "\n",
    "# Compute the average interpolated coherence data\n",
    "average_coherence_final = (interp_coherence1 + interp_coherence2 + interp_coherence3 + interp_coherence4) / 4\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# Plotting\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']  # Colors\n",
    "titles = ['North-East', 'North-West', 'East-West']\n",
    "amps = [5, 10, 20, 30, 40, 50, 60]  \n",
    "xticks_values = [10, 20, 30, 40, 50]  # Manually set x-axis ticks\n",
    "\n",
    "for j in range(3):\n",
    "    fig, ax = plt.subplots(dpi=400, figsize=(5, 5))\n",
    "    for k in range(7):\n",
    "        ax.semilogy(f, average_coherence_final[:, k, j], label=f'{amps[k]}A', color=colors[k])\n",
    "\n",
    "    ax.set_title(f'{titles[j]}', fontsize=27, fontweight='bold')\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=25, fontweight='bold')\n",
    "    ax.set_ylabel('Coherence', fontsize=25, fontweight='bold')\n",
    "    ax.set_xlim([1, 50])\n",
    "    ax.set_xticks(xticks_values)  # Set x-axis ticks\n",
    "    ax.set_xticklabels([str(tick) for tick in xticks_values])  # Ensure labels are strings\n",
    "    ax.set_ylim([10**(-3), 10**(0)])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=23, width=2, length=5) \n",
    "    ax.legend(loc='lower right', fontsize=14.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
